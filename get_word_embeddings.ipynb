{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6196/2472899866.py:4: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "/home/aishik/anaconda3/envs/R106/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from dotenv import load_dotenv\n",
    "# load_dotenv()\n",
    "\n",
    "from openai import OpenAI\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    model_name = \"BAAI/bge-base-en-v1.5\"\n",
    "    words = \"data/reddit.US.txt.tok.clean.cleanedforw2v_0.w2v\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_words(w2v_file):\n",
    "    words = []\n",
    "    with open(w2v_file, 'r') as f:\n",
    "        for line in f:\n",
    "            vect = line.strip().rsplit()\n",
    "            word = vect[0]\n",
    "            words.append(word)\n",
    "        \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = load_words(CFG.words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(CFG.professions) as file:\n",
    "#     data = json.load(file)\n",
    "\n",
    "# professions = [data_[0][0] for data_ in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(CFG.male_words, 'r') as file:\n",
    "#     # Read the file\n",
    "#     data = file.read()\n",
    "\n",
    "# # Split the file into words\n",
    "# male_words = data.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(CFG.female_words, 'r') as file:\n",
    "#     # Read the file\n",
    "#     data = file.read()\n",
    "\n",
    "# # Split the file into words\n",
    "# female_words = data.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "# client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# def get_embedding(text, model=\"text-embedding-ada-002\"):\n",
    "#    text = text.replace(\"\\n\", \" \")\n",
    "#    return client.embeddings.create(input = [text], model=model).data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".gitattributes: 100%|██████████| 1.52k/1.52k [00:00<00:00, 3.11MB/s]\n",
      "1_Pooling/config.json: 100%|██████████| 190/190 [00:00<00:00, 765kB/s]\n",
      "README.md: 100%|██████████| 90.2k/90.2k [00:00<00:00, 11.3MB/s]\n",
      "config.json: 100%|██████████| 777/777 [00:00<00:00, 2.76MB/s]\n",
      "config_sentence_transformers.json: 100%|██████████| 124/124 [00:00<00:00, 390kB/s]\n",
      "model.safetensors: 100%|██████████| 438M/438M [00:22<00:00, 19.2MB/s] \n",
      "pytorch_model.bin: 100%|██████████| 438M/438M [00:22<00:00, 19.3MB/s] \n",
      "sentence_bert_config.json: 100%|██████████| 52.0/52.0 [00:00<00:00, 158kB/s]\n",
      "special_tokens_map.json: 100%|██████████| 125/125 [00:00<00:00, 717kB/s]\n",
      "tokenizer.json: 100%|██████████| 711k/711k [00:00<00:00, 11.6MB/s]\n",
      "tokenizer_config.json: 100%|██████████| 366/366 [00:00<00:00, 1.21MB/s]\n",
      "vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 1.16MB/s]\n",
      "modules.json: 100%|██████████| 349/349 [00:00<00:00, 390kB/s]\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(CFG.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': True}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': True, 'pooling_mode_mean_tokens': False, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       "  (2): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44895, 768)\n"
     ]
    }
   ],
   "source": [
    "word_embeddings = model.encode(words)\n",
    "print(word_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# male_word_embeddings = model.encode(male_words)\n",
    "# female_word_embeddings = model.encode(female_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# professions_embeddings = model.encode(professions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "np.save(f'word_embeddings/{CFG.model_name.replace(\"/\", \"-\")}-embeddings.npy', word_embeddings)\n",
    "# np.save(f'{CFG.model_name.replace(\"/\", \"-\")}-male-embeddings.npy', male_word_embeddings)\n",
    "# np.save(f'{CFG.model_name.replace(\"/\", \"-\")}-female-embeddings.npy', female_word_embeddings)\n",
    "# np.save(f'{CFG.model_name.replace(\"/\", \"-\")}-professions-embeddings.npy', professions_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R106",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
