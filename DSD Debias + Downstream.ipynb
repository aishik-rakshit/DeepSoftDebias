{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":13207,"status":"ok","timestamp":1730357149241,"user":{"displayName":"Aishik Rakshit","userId":"15122983906308089605"},"user_tz":-330},"id":"uoB6Mujms2_m"},"outputs":[],"source":["!pip -q install accelerate\n","!pip -q install bitsandbytes\n","!pip -q install huggingface_hub\n","!pip -q install contractions\n","!pip -q install datasets"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1730357149242,"user":{"displayName":"Aishik Rakshit","userId":"15122983906308089605"},"user_tz":-330},"id":"tc8ffmKqtWCd","outputId":"b776eeda-2cd4-45af-d591-81ef2fc30410"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/DSD\n"]}],"source":["%cd /content/drive/MyDrive/DSD"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":407,"referenced_widgets":["6c6f2aae5a5842dcb8f484f4975c5455","4ade34a2c7d345e1a3c08d508f18c1f8","1a6d41a5bf33403cb040875872816dfa","e98cd7cc8bd9452abd7756b92787c9d3","d54c4f695adb4a9db42e6b71e87864f7","075636d3c1f64936a427d5d3851933ee","87636363c1f942edae2f6416153dd78a","a4aba6b7f3d547ddbb17adedf6a64d6a","983c3a905a064488a1d18eea117fb7ca","a34919f15eee447395b8404a0b579391","f168ced8d2c442439022b23310a07440","a9f52f78cfc24eb1a2d3064f02c018e0","62e94f1c1c90427c87589d9b6d10e737","ee4ad713e8ad4c07a7c939bfeebc95f1","f960f975d1b24158bc5041b112bda1da","33c4b25fc3d8477891cbc4ee89c30c4c","5358ef271e1d4315a188b0142770e6ec"]},"executionInfo":{"elapsed":6782,"status":"ok","timestamp":1730357156021,"user":{"displayName":"Aishik Rakshit","userId":"15122983906308089605"},"user_tz":-330},"id":"DFnls1DHtg94","outputId":"7d0405c8-07df-4e85-8dd0-d81b06c8a967"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]},{"output_type":"display_data","data":{"text/plain":["VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c6f2aae5a5842dcb8f484f4975c5455"}},"metadata":{}}],"source":["import os\n","import gc\n","import json\n","import re\n","import csv\n","import string\n","import pickle\n","import numpy as np\n","import pandas as pd\n","import nltk\n","from nltk.corpus import stopwords\n","from tqdm import tqdm\n","from collections import Counter, defaultdict\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","\n","from scipy import spatial\n","from scipy.stats import ttest_rel, spearmanr, pearsonr\n","from sklearn.decomposition import PCA\n","from sklearn.metrics.pairwise import cosine_similarity\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, f1_score\n","\n","from xgboost import XGBClassifier\n","\n","import contractions\n","from gensim.models.keyedvectors import Word2VecKeyedVectors\n","from gensim.models import Word2Vec\n","\n","from transformers import AutoModel, AutoTokenizer\n","\n","import torch\n","import torch.nn as nn\n","from torch import optim\n","import torch.nn.functional as F\n","from torch.utils.data import TensorDataset, DataLoader, Dataset\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","from huggingface_hub import notebook_login\n","from datasets import load_dataset\n","notebook_login()"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1730357156021,"user":{"displayName":"Aishik Rakshit","userId":"15122983906308089605"},"user_tz":-330},"id":"UsFGmk_HtqDz"},"outputs":[],"source":["class CFG:\n","    model_name = \"meta-llama/Meta-Llama-3-8B\"\n","    model_type = '2L'\n","    topic = 'race'\n","    mode = 'role'\n","    max_len = 4\n","    batch_size = 64\n","    num_workers = 12\n","    adam_lr = 1e-5\n","    sgd_lr = 1e-8\n","\n","    base_path = \"/content/drive/MyDrive/DSD/\"\n","    vocabPath = f\"{topic}_attributes_optm.json\"\n","    outprefix =  model_name.replace(\"/\", \"-\")+\"-\"+topic\n","\n","    embedding_dict_data = f\"word-embeddings/{model_name.replace('/','_')}_word_embeddings_reddit-l2.pkl\"\n","    stereoset_data = \"stereoset.json\"\n","    crows_data = \"crows_pairs.csv\"\n","    cross_ner_data = \"cross_ner.txt\"\n","    stanford_sentiment_treebank_data = \"stanford_sentiment_treebank.csv\"\n","\n","    stsb_word_vectors = f\"word-embeddings/{model_name.replace('/','_')}_word_embeddings_stsb.pkl\"\n","    cross_ner_word_vectors = f\"word-embeddings/{model_name.replace('/','_')}_word_embeddings_cross_ner.pkl\"\n","    sst_word_vectors = f\"word-embeddings/{model_name.replace('/','_')}_word_embeddings_sst.pkl\"\n","    mrpc_word_vectors = f\"word-embeddings/{model_name.replace('/','_')}_word_embeddings_mrpc.pkl\"\n","    mnli_word_vectors = f\"word-embeddings/{model_name.replace('/','_')}_word_embeddings_mnli.pkl\"\n","    wnli_word_vectors = f\"word-embeddings/{model_name.replace('/','_')}_word_embeddings_wnli.pkl\"\n","    rte_word_vectors = f\"word-embeddings/{model_name.replace('/','_')}_word_embeddings_rte.pkl\"\n","\n","    results_filename = \"results/results_debiasing.csv\"\n","    downstream_results_filename = \"results/results_downstream.csv\"\n","\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1730357156021,"user":{"displayName":"Aishik Rakshit","userId":"15122983906308089605"},"user_tz":-330},"id":"FzIaBkJWNoUj"},"outputs":[],"source":["results = dict()\n","results['model_name'] = CFG.model_name\n","results['topic'] = CFG.topic\n","\n","downstream_results = dict()\n","downstream_results['model_name'] = CFG.model_name\n","downstream_results['topic'] = CFG.topic"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1730357156021,"user":{"displayName":"Aishik Rakshit","userId":"15122983906308089605"},"user_tz":-330},"id":"3zbU0jBgjPm9"},"outputs":[],"source":["def isValidWord(word):\n","    return all([c.isalpha() for c in word])\n","\n","def pruneWordVecs(wordVecs):\n","    newWordVecs = {}\n","    for word, vec in wordVecs.items():\n","        valid=True\n","        if(not isValidWord(word)):\n","            valid = False\n","        if(valid):\n","            newWordVecs[word] = vec\n","    return newWordVecs\n","\n","def load_words(w2v_files):\n","    words = []\n","    for w2v_file in w2v_files:\n","        with open(w2v_file, 'r') as f:\n","            for line in f:\n","                vect = line.strip().rsplit()\n","                word = vect[0]\n","                words.append(word)\n","\n","    return words\n","\n","def load_analogy_templates(json_filepath, mode):\n","\twith open(json_filepath, \"r\") as f:\n","\t\tloadedData = json.load(f)\n","\t\treturn loadedData[\"analogy_templates\"][mode]\n","\n","def load_test_terms(json_filepath):\n","\twith open(json_filepath, \"r\") as f:\n","\t\tloadedData = json.load(f)\n","\t\treturn loadedData[\"testTerms\"]\n","\n","def load_eval_terms(json_filepath, mode):\n","\twith open(json_filepath, \"r\") as f:\n","\t\tloadedData = json.load(f)\n","\t\treturn loadedData[\"eval_targets\"], loadedData[\"analogy_templates\"][mode].values()\n","\n","def load_def_sets(json_filepath):\n","\twith open(json_filepath, \"r\") as f:\n","\t\tloadedData = json.load(f)\n","\t\treturn {i: v for i, v in enumerate(loadedData[\"definite_sets\"])}"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1730357156021,"user":{"displayName":"Aishik Rakshit","userId":"15122983906308089605"},"user_tz":-330},"id":"A6S8K-FTk_ro"},"outputs":[],"source":["class WordsDataset(Dataset):\n","    def __init__(self, words, tokenizer):\n","        self.words = words\n","        self.tokenizer = tokenizer\n","\n","    def __len__(self):\n","        return len(self.words)\n","\n","    def __getitem__(self, idx):\n","        word = self.words[idx]\n","        return self.tokenizer(word, padding='max_length', max_length = CFG.max_len, truncation = True, return_tensors=\"pt\")"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":2407,"status":"ok","timestamp":1730357158425,"user":{"displayName":"Aishik Rakshit","userId":"15122983906308089605"},"user_tz":-330},"id":"ER-FnN1A7NE0"},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained(CFG.model_name)\n","if tokenizer.pad_token is None:\n","    tokenizer.pad_token = tokenizer.eos_token"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":84,"referenced_widgets":["9d60968f2fd2495bbe6e863e37e3d789","83f88bb619e14aebbe23eea55fc03dcd","a001c13232de47299021bd7d1fbf16ce","f914a2573f7c4ec786b1b3784d001565","064ba35d5bd546c191d66fd27c9b01f0","c96875a3651e46c1b1f2aa3197450784","d11f92ceb6c84794a92581dba8501db6","182ee0900a7f4b0b9204b2f55a14f760","ffbeb6421bbd425fbd5f2846da278851","1335d11d343a4b88878bac2edeb31d8a","7c1a54f6808b43de8fe91b31a4b175ce"]},"executionInfo":{"elapsed":12669,"status":"ok","timestamp":1730357171093,"user":{"displayName":"Aishik Rakshit","userId":"15122983906308089605"},"user_tz":-330},"id":"tGq-54nblvQp","outputId":"efed6725-dcd0-4657-b8e0-124bdbb22ee4"},"outputs":[{"output_type":"stream","name":"stderr","text":["The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n","`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"]},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d60968f2fd2495bbe6e863e37e3d789"}},"metadata":{}}],"source":["def mean_pooling(model_output, attention_mask):\n","    token_embeddings = model_output[0]  # First element of model_output contains all token embeddings\n","    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n","    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n","\n","class Model(torch.nn.Module):\n","    def __init__(self, model_name):\n","        super(Model, self).__init__()\n","        self.encoder = AutoModel.from_pretrained(model_name, load_in_8bit = True)\n","\n","    def forward(self, input_ids, attention_mask):\n","        model_output = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n","        sentence_embeddings = mean_pooling(model_output, attention_mask)\n","        return sentence_embeddings\n","\n","lm_model = Model(CFG.model_name).to(CFG.device)"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1730357171093,"user":{"displayName":"Aishik Rakshit","userId":"15122983906308089605"},"user_tz":-330},"id":"g_m8XFVLAcum"},"outputs":[],"source":["def get_word_embeddings(words, model):\n","    model.eval()\n","    words_dataset = WordsDataset(words, tokenizer)\n","    words_dataloader = DataLoader(words_dataset, batch_size=CFG.batch_size, shuffle=False, num_workers = CFG.num_workers)\n","    embeddings = []\n","    for batch in tqdm(words_dataloader, total = len(words_dataloader)):\n","        input_ids = torch.squeeze(batch['input_ids'].to(CFG.device), axis = 1)\n","        attention_mask = torch.squeeze(batch['attention_mask'].to(CFG.device), axis = 1)\n","        batch_embeddings = model(input_ids, attention_mask).detach().cpu().numpy()\n","        embeddings.append(batch_embeddings)\n","    # concatenate the embeddings into a single numpy array\n","    embeddings = np.concatenate(embeddings, axis=0)\n","    del words_dataset, words_dataloader\n","    gc.collect()\n","    return embeddings"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4606,"status":"ok","timestamp":1730357175697,"user":{"displayName":"Aishik Rakshit","userId":"15122983906308089605"},"user_tz":-330},"id":"3y7XEWK_7Pqm","outputId":"fca500d2-01fd-4a70-c523-53813e904a04"},"outputs":[{"output_type":"stream","name":"stderr","text":["  0%|          | 0/1 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n","100%|██████████| 1/1 [00:03<00:00,  3.76s/it]\n"]}],"source":["analogyTemplates = load_analogy_templates(CFG.vocabPath, CFG.mode)\n","defSets = load_def_sets(CFG.vocabPath)\n","testTerms = load_test_terms(CFG.vocabPath)\n","evalTargets, evalAttrs = load_eval_terms(CFG.vocabPath, CFG.mode)\n","\n","CFG.subspace_dim = len(defSets)*len(defSets[0])\n","\n","neutral_words = []\n","for value in analogyTemplates.values():\n","    neutral_words.extend(value)\n","\n","neutral_word_embeddings = get_word_embeddings(neutral_words, lm_model)\n","neutral_embedding_dict = {word: embedding for word, embedding in zip(neutral_words, neutral_word_embeddings)}\n","embedding_dim = neutral_word_embeddings.shape[-1]\n","CFG.embedding_dim = embedding_dim"]},{"cell_type":"code","source":["print(defSets)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_o4kqkoxJt4x","executionInfo":{"status":"ok","timestamp":1730357175697,"user_tz":-330,"elapsed":4,"user":{"displayName":"Aishik Rakshit","userId":"15122983906308089605"}},"outputId":"a2af2d73-2a7b-4343-c893-23f3cb4fca8a"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["{0: ['black', 'caucasian', 'asian'], 1: ['african', 'caucasian', 'asian'], 2: ['black', 'white', 'asian'], 3: ['africa', 'america', 'asia'], 4: ['africa', 'america', 'china'], 5: ['africa', 'europe', 'asia']}\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rc0VBB477YAW"},"outputs":[],"source":["def identify_bias_subspace(vocab, def_sets, subspace_dim, embedding_dim):\n","    \"\"\"\n","    Similar to bolukbasi's implementation at\n","    https://github.com/tolga-b/debiaswe/blob/master/debiaswe/debias.py\n","\n","    vocab - dictionary mapping words to embeddings\n","    def_sets - sets of words that represent extremes? of the subspace\n","            we're interested in (e.g. man-woman, boy-girl, etc. for binary gender)\n","    subspace_dim - number of vectors defining the subspace\n","    embedding_dim - dimensions of the word embeddings\n","    \"\"\"\n","    # calculate means of defining sets\n","    means = {}\n","    for k, v in def_sets.items():\n","        wSet = []\n","        for w in v:\n","            try:\n","                wSet.append(vocab[w])\n","            except KeyError as e:\n","                pass\n","        set_vectors = np.array(wSet)\n","        means[k] = np.mean(set_vectors, axis=0)\n","\n","    # calculate vectors to perform PCA\n","    matrix = []\n","    for k, v in def_sets.items():\n","        wSet = []\n","        for w in v:\n","            try:\n","                wSet.append(vocab[w])\n","            except KeyError as e:\n","                pass\n","        set_vectors = np.array(wSet)\n","        diffs = set_vectors - means[k]\n","        matrix.append(diffs)\n","\n","    matrix = np.concatenate(matrix)\n","\n","    pca = PCA(n_components=subspace_dim)\n","    pca.fit(matrix)\n","\n","    return pca.components_\n","\n","with open(CFG.embedding_dict_data, 'rb') as f:\n","    embedding_dict = pickle.load(f)\n","embedding_dict = pruneWordVecs(embedding_dict)\n","subspace = identify_bias_subspace(embedding_dict, defSets, CFG.subspace_dim, CFG.embedding_dim)[:CFG.subspace_dim]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":198057,"status":"ok","timestamp":1726151743179,"user":{"displayName":"Aishik Rakshit","userId":"15122983906308089605"},"user_tz":-330},"id":"S5DqIK9_APlA","outputId":"c94bf5ac-5eb3-4784-b299-c8fdcdb94176"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loss @ Epoch #0: tensor(1.4905e+12, grad_fn=<AddBackward0>)\n","Loss @ Epoch #1: tensor(6.0138e+13, grad_fn=<AddBackward0>)\n","Loss @ Epoch #2: tensor(2.4337e+15, grad_fn=<AddBackward0>)\n","Loss @ Epoch #3: tensor(9.8490e+16, grad_fn=<AddBackward0>)\n","Loss @ Epoch #4: tensor(3.9858e+18, grad_fn=<AddBackward0>)\n","Loss @ Epoch #5: tensor(inf, grad_fn=<AddBackward0>)\n","Loss @ Epoch #6: tensor(inf, grad_fn=<AddBackward0>)\n","Loss @ Epoch #7: tensor(inf, grad_fn=<AddBackward0>)\n","Loss @ Epoch #8: tensor(inf, grad_fn=<AddBackward0>)\n","Loss @ Epoch #9: tensor(inf, grad_fn=<AddBackward0>)\n","Optimization Completed, normalizing vector transform\n"]}],"source":["def equalize_and_soften(vocab, words, bias_subspace, embedding_dim, l=0.2, verbose=True):\n","    vocabIndex, vocabVectors = zip(*vocab.items())\n","    vocabIndex = {i:label for i, label in enumerate(vocabIndex)}\n","    Neutrals = torch.tensor([vocab[w] for w in words]).float().t()\n","\n","    Words = torch.tensor(vocabVectors).float().t()\n","\n","    # perform SVD on W to reduce memory and computational costs\n","    # based on suggestions in supplementary material of Bolukbasi et al.\n","    u, s, _ = torch.svd(Words)\n","    s = torch.diag(s)\n","\n","    # precompute\n","    t1 = s.mm(u.t())\n","    t2 = u.mm(s)\n","\n","    Transform = torch.randn(embedding_dim, embedding_dim).float()\n","    BiasSpace = torch.tensor(bias_subspace).reshape(embedding_dim, -1).float()\n","\n","    Neutrals.requires_grad = False\n","    Words.requires_grad = False\n","    BiasSpace.requires_grad = False\n","    Transform.requires_grad = True\n","\n","    epochs = 10\n","    optimizer = torch.optim.SGD([Transform], lr=CFG.sgd_lr, momentum=0.0)\n","\n","    for i in range(0, epochs):\n","        TtT = torch.mm(Transform.t(), Transform)\n","        norm1 = (t1.mm(TtT - torch.eye(embedding_dim)).mm(t2)).norm(p=2)\n","\n","        norm2 = (Neutrals.t().mm(TtT).mm(BiasSpace)).norm(p=2)\n","\n","        loss = norm1 + l * norm2\n","        norm1 = None\n","        norm2 = None\n","\n","        loss.backward()\n","        optimizer.step()\n","        optimizer.zero_grad()\n","\n","        if(verbose):\n","            print(\"Loss @ Epoch #\" + str(i) + \":\", loss)\n","\n","    if(verbose):\n","        print(\"Optimization Completed, normalizing vector transform\")\n","\n","    debiasedVectors = {}\n","    for i, w in enumerate(Words.t()):\n","        transformedVec = torch.mm(Transform, w.view(-1, 1))\n","        debiasedVectors[vocabIndex[i]] = ( transformedVec / transformedVec.norm(p=2) ).detach().numpy().flatten()\n","\n","    return debiasedVectors, Transform\n","\n","soft_word_vectors, debias_matrix = equalize_and_soften(embedding_dict, neutral_words, subspace, CFG.embedding_dim)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tecx2IpsCW1w"},"outputs":[],"source":["class ResidualBlock(nn.Module):\n","    def __init__(self, input_dim, output_dim):\n","        super(ResidualBlock, self).__init__()\n","        self.fc1 = nn.Linear(input_dim, output_dim)\n","        self.fc2 = nn.Linear(output_dim, output_dim)\n","        if input_dim != output_dim:\n","            self.shortcut = nn.Linear(input_dim, output_dim)\n","        else:\n","            self.shortcut = nn.Identity()\n","\n","    def forward(self, x):\n","        identity = self.shortcut(x)\n","        out = F.relu(self.fc1(x))\n","        out = self.fc2(out)\n","        out += identity\n","        return out\n","\n","class TransformNet1L(nn.Module):\n","    def __init__(self, input_dim, output_dim):\n","        super(TransformNet1L, self).__init__()\n","        self.resblock1 = ResidualBlock(input_dim, output_dim)\n","\n","    def forward(self, x):\n","        x = self.resblock1(x)\n","        return x\n","\n","class TransformNet2L(nn.Module):\n","    def __init__(self, input_dim, output_dim):\n","        super(TransformNet2L, self).__init__()\n","        self.resblock1 = ResidualBlock(input_dim, output_dim*2)\n","        self.resblock2 = ResidualBlock(output_dim*2, output_dim)\n","\n","    def forward(self, x):\n","        x = self.resblock1(x)\n","        x = self.resblock2(x)\n","        return x\n","\n","class TransformNet3L(nn.Module):\n","    def __init__(self, input_dim, output_dim):\n","        super(TransformNet3L, self).__init__()\n","        self.resblock1 = ResidualBlock(input_dim, output_dim*2)\n","        self.resblock2 = ResidualBlock(output_dim*2, output_dim*2)\n","        self.resblock3 = ResidualBlock(output_dim*2, output_dim)\n","\n","    def forward(self, x):\n","        x = self.resblock1(x)\n","        x = self.resblock2(x)\n","        x = self.resblock3(x)\n","        return x\n","\n","if(CFG.model_type == \"1L\"):\n","    TransformNet = TransformNet1L\n","    embedding_dim = CFG.embedding_dim\n","elif(CFG.model_type == \"2L\"):\n","    TransformNet = TransformNet2L\n","    embedding_dim = CFG.embedding_dim\n","elif(CFG.model_type == \"3L\"):\n","    TransformNet = TransformNet3L\n","    embedding_dim = CFG.embedding_dim"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"grHRExIaGfgr","executionInfo":{"status":"ok","timestamp":1726152139214,"user_tz":-330,"elapsed":396038,"user":{"displayName":"Aishik Rakshit","userId":"15122983906308089605"}},"outputId":"714bc4d6-b06a-4db7-e6e7-9c3bca2847b7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loss @ Epoch #0: 56768092.0\n","Loss @ Epoch #10: 32844776.0\n","Loss @ Epoch #20: 8199089.0\n","Loss @ Epoch #30: 6973820.0\n","Loss @ Epoch #50: 2225917.5\n","Loss @ Epoch #60: 1941577.875\n","Loss @ Epoch #70: 1795423.0\n","Loss @ Epoch #80: 1685937.75\n","Loss @ Epoch #90: 1591980.75\n","Optimization Completed, normalizing vector transform\n"]}],"source":["def equalize_and_soften_DSD(vocab, words, eq_sets, bias_subspace, embedding_dim, l=0.2, verbose=True):\n","    vocabIndex, vocabVectors = zip(*vocab.items())\n","    vocabIndex = {i:label for i, label in enumerate(vocabIndex)}\n","    Neutrals = torch.tensor([vocab[w] for w in words]).float().t().to(CFG.device)\n","\n","    Words = torch.tensor(vocabVectors).float().t().to(CFG.device)\n","\n","    Transform = TransformNet(embedding_dim, embedding_dim).to(CFG.device)\n","    BiasSpace = torch.tensor(bias_subspace).reshape(embedding_dim, -1).float().to(CFG.device)\n","\n","    Neutrals.requires_grad = False\n","    Words.requires_grad = False\n","    BiasSpace.requires_grad = False\n","\n","    epochs = 100\n","    optimizer = optim.Adam(Transform.parameters(), lr=CFG.adam_lr)\n","\n","    identity_matrix = torch.eye(embedding_dim).to(CFG.device)\n","\n","    Words = Words.t()\n","    for i in range(0, epochs):\n","        transformed_words = Transform(Words)\n","\n","        TtT = torch.matmul(transformed_words.t(), transformed_words)\n","        norm1 = torch.norm(torch.matmul(transformed_words.t(), transformed_words) - identity_matrix)\n","\n","        norm2 = torch.norm(torch.matmul(torch.matmul(Neutrals.t(), TtT), BiasSpace))\n","\n","        # norm1 = torch.norm(torch.matmul(transformed_words.t(), transformed_words) - identity_matrix)\n","\n","        # norm2 = torch.norm(torch.matmul(Neutrals.t(), transformed_words.t()))\n","\n","        loss = norm1 + l * norm2\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        if(verbose and (i%10==0)):\n","            print(\"Loss @ Epoch #\" + str(i) + \":\", loss.item())\n","\n","    if(verbose):\n","        print(\"Optimization Completed, normalizing vector transform\")\n","\n","    debiasedVectors = {}\n","    for i, w in enumerate(Words):\n","        transformedVec = Transform(w.view(1, -1))\n","        debiasedVectors[vocabIndex[i]] = ( transformedVec / transformedVec.norm(p=2) ).detach().cpu().numpy().flatten()\n","\n","    return debiasedVectors, Transform\n","\n","DSD_soft_word_vectors, debias_model = equalize_and_soften_DSD(embedding_dict, neutral_words, defSets.values(), subspace, embedding_dim)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CIc591p_T7OC"},"outputs":[],"source":["def scoredAnalogyAnswers(a,b,x, keyedVecs, thresh=12.5):\n","\twords = [w for w in keyedVecs.key_to_index.keys() if np.linalg.norm(np.array(keyedVecs[w])-np.array(keyedVecs[x])) < thresh]\n","\n","\tdef cos(a,b,x,y):\n","\t\taVec = np.array(keyedVecs[a])\n","\t\tbVec = np.array(keyedVecs[b])\n","\t\txVec = np.array(keyedVecs[x])\n","\t\tyVec = np.array(keyedVecs[y])\n","\t\tnumerator = (aVec-bVec).dot(xVec-yVec)\n","\t\tdenominator = np.linalg.norm(aVec-bVec)*np.linalg.norm(xVec-yVec)\n","\t\treturn numerator/(denominator if denominator != 0 else 1e-6)\n","\n","\treturn sorted([(cos(a,b,x,y), a,b,x,y) for y in words], reverse=True)\n","\n","def generateAnalogies(analogyTemplates, keyedVecs):\n","    expandedAnalogyTemplates = []\n","    for A, stereotypes in analogyTemplates.items():\n","        for B, _ in analogyTemplates.items():\n","            if(A != B):\n","                for stereotype in stereotypes:\n","                    expandedAnalogyTemplates.append([A, stereotype, B])\n","\n","    analogies = []\n","    outputGroups = []\n","    for a,b,x in expandedAnalogyTemplates:\n","        outputs = scoredAnalogyAnswers(a,b,x,keyedVecs)\n","        formattedOutput = []\n","\n","        for score, a_w, b_w, x_w, y_w in outputs:\n","\n","            analogy = str(a_w) + \" is to \" + str(b_w) + \" as \" + str(x_w) + \" is to \" + str(y_w)\n","            analogyRaw = [a_w, b_w, x_w, y_w]\n","            analogies.append([score, analogy, analogyRaw])\n","            formattedOutput.append([score, analogy, analogyRaw])\n","        outputGroups.append(formattedOutput)\n","\n","    analogies = sorted(analogies, key=lambda x:-x[0])\n","    return analogies, outputGroups\n","\n","def convert_legacy_to_keyvec(legacy_w2v):\n","    dim = len(legacy_w2v[list(legacy_w2v.keys())[0]])\n","    vectors = Word2VecKeyedVectors(dim)\n","\n","    ws = []\n","    vs = []\n","\n","    for word, vect in legacy_w2v.items():\n","        ws.append(word)\n","        vs.append(vect)\n","        assert(len(vect) == dim)\n","    vectors.add_vectors(ws, vs, replace=True)\n","    return vectors\n","\n","def multiclass_evaluation(embeddings, targets, attributes):\n","\ttargets_eval = []\n","\tfor targetSet in targets:\n","\t\tfor target in targetSet:\n","\t\t\tfor attributeSet in attributes:\n","\t\t\t\ttargets_eval.append(_unary_s(embeddings, target, attributeSet))\n","\tm_score = np.mean(targets_eval)\n","\treturn m_score, targets_eval\n","\n","def _unary_s(embeddings, target, attributes):\n","\treturn np.mean([ spatial.distance.cosine(embeddings[target], embeddings[ai]) for ai in attributes ])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nCsutJW4bOTQ","executionInfo":{"status":"ok","timestamp":1726152139214,"user_tz":-330,"elapsed":5,"user":{"displayName":"Aishik Rakshit","userId":"15122983906308089605"}},"outputId":"b6964ef2-163f-4cb8-d2be-db428f7ed1c7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Biased Evaluation Results\n","Biased MAC: 0.2542485188204359\n"]}],"source":["print(\"Biased Evaluation Results\")\n","biasedMAC, biasedDistribution = multiclass_evaluation(embedding_dict, evalTargets, evalAttrs)\n","print(\"Biased MAC:\", biasedMAC)\n","results['Biased MAC'] = np.round(biasedMAC, 3)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BcyqgeO0bPC-","executionInfo":{"status":"ok","timestamp":1726152139214,"user_tz":-330,"elapsed":4,"user":{"displayName":"Aishik Rakshit","userId":"15122983906308089605"}},"outputId":"50f7e568-1a50-4cd6-93ee-f3dfd84ea01e"},"outputs":[{"output_type":"stream","name":"stdout","text":["SOFT Debiased Evaluation Results\n","soft MAC: 2.0557321837383372e-08\n","soft Debiased Cosine difference t-test 1.2217354183068485e-24\n","DSD Evaluation Results\n","DSD MAC: 0.9391052622546912\n","soft Debiased DSD Cosine difference t-test 3.604249838458218e-36\n"]}],"source":["print(\"SOFT Debiased Evaluation Results\")\n","debiasedMAC, debiasedDistribution = multiclass_evaluation(soft_word_vectors, evalTargets, evalAttrs)\n","print(\"soft MAC:\", debiasedMAC)\n","\n","statistics, pvalue = ttest_rel(biasedDistribution, debiasedDistribution)\n","print(\"soft Debiased Cosine difference t-test\", pvalue)\n","\n","results['Soft-Debiased MAC'] = np.round(debiasedMAC, 3)\n","results['soft-Debiased PValue'] = pvalue\n","\n","print(\"DSD Evaluation Results\")\n","debiasedMAC, debiasedDistribution = multiclass_evaluation(DSD_soft_word_vectors, evalTargets, evalAttrs)\n","print(\"DSD MAC:\", debiasedMAC)\n","\n","statistics, pvalue = ttest_rel(biasedDistribution, debiasedDistribution)\n","print(\"soft Debiased DSD Cosine difference t-test\", pvalue)\n","\n","results['DSD MAC'] = np.round(debiasedMAC, 3)\n","results['DSD PValue'] = pvalue"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MPMRldp2b9z2"},"outputs":[],"source":["def avg_feature_vector(sentence, model, num_features):\n","    words = sentence.split()\n","    feature_vec = np.zeros((num_features, ), dtype='float32')\n","    n_words = 0\n","    for word in words:\n","        if word in list(model.keys()):\n","            n_words += 1\n","            feature_vec = np.add(feature_vec, model[word])\n","    if (n_words > 0):\n","        feature_vec = np.divide(feature_vec, n_words)\n","    return feature_vec"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CPNvELHdNGpg"},"outputs":[],"source":["def get_stereotype_score(word_vectors, data):\n","    total_samples = 0\n","    stereotypical_samples = 0\n","\n","    # Iterate over the data\n","    for item in data:\n","        context = item['context']\n","        stereo = item['stereotype']\n","        antistereo = item['anti-stereotype']\n","\n","        # Calculate sentence embeddings\n","        context_vec = avg_feature_vector(context, word_vectors, num_features=CFG.embedding_dim)\n","        stereo_vec = avg_feature_vector(stereo, word_vectors, num_features=CFG.embedding_dim)\n","        antistereo_vec = avg_feature_vector(antistereo, word_vectors, num_features=CFG.embedding_dim)\n","\n","        context_vec = context_vec/np.linalg.norm(context_vec)\n","        stereo_vec = stereo_vec/np.linalg.norm(stereo_vec)\n","        antistereo_vec = antistereo_vec/np.linalg.norm(antistereo_vec)\n","\n","        # Calculate cosine similarity\n","        simstereo = spatial.distance.cosine(context_vec, stereo_vec)\n","        simantistereo = spatial.distance.cosine(context_vec, antistereo_vec)\n","\n","        if simstereo > simantistereo:\n","            stereotypical_samples += 1\n","        total_samples += 1\n","\n","    # Calculate stereotype score\n","    stereotype_score = stereotypical_samples*100 / total_samples\n","    print('Stereotype Score:', stereotype_score)\n","    return stereotype_score"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"161ubE22NJ8o"},"outputs":[],"source":["with open(CFG.stereoset_data) as f:\n","    data = json.load(f)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uZjX0WyvOiIt"},"outputs":[],"source":["topic_data = [item for item in data if item['bias_type']==CFG.topic]\n","\n","stereoset_data_processed = []\n","\n","for item in topic_data:\n","    data_dict = defaultdict()\n","    data_dict['context'] = item['context']\n","    for item_ in item['sentences']:\n","        if item_['gold_label'] == 'stereotype':\n","            data_dict['stereotype'] = item_['sentence']\n","        elif item_['gold_label'] == 'anti-stereotype':\n","            data_dict['anti-stereotype'] = item_['sentence']\n","    stereoset_data_processed.append(data_dict)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zlbxOvqANQcG","executionInfo":{"status":"ok","timestamp":1726152151946,"user_tz":-330,"elapsed":11553,"user":{"displayName":"Aishik Rakshit","userId":"15122983906308089605"}},"outputId":"3d0d6235-2ada-4b48-af0d-180548374b99"},"outputs":[{"output_type":"stream","name":"stdout","text":["Stereotype Score: 19.834710743801654\n","Stereotype Score: 50.0\n"]}],"source":["results['Soft-Debiased SS'] = get_stereotype_score(soft_word_vectors, stereoset_data_processed)\n","results['DSD SS'] = get_stereotype_score(DSD_soft_word_vectors, stereoset_data_processed)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jCzrDRj8ScNA"},"outputs":[],"source":["def read_crows_data(input_file):\n","    \"\"\"\n","    Load data into pandas DataFrame format.\n","    \"\"\"\n","\n","    df_data = pd.DataFrame(columns=['sent1', 'sent2', 'direction', 'bias_type'])\n","\n","    with open(input_file) as f:\n","        reader = csv.DictReader(f)\n","        for row in reader:\n","            direction, gold_bias = '_', '_'\n","            direction = row['stereo_antistereo']\n","            bias_type = row['bias_type']\n","\n","            sent1, sent2 = '', ''\n","            if direction == 'stereo':\n","                sent1 = row['sent_more']\n","                sent2 = row['sent_less']\n","            else:\n","                sent1 = row['sent_less']\n","                sent2 = row['sent_more']\n","\n","            df_item = {'sent1': sent1,\n","                       'sent2': sent2,\n","                       'direction': direction,\n","                       'bias_type': bias_type}\n","            df_data = df_data._append(df_item, ignore_index=True)\n","\n","    return df_data\n","\n","def replace_words(text):\n","    def repl(match):\n","        if match.group(0).endswith('woman'):\n","            return 'woman'\n","        elif match.group(0).endswith('man'):\n","            return 'man'\n","    return re.sub(r'\\b\\w*(man|woman)\\b', repl, text)\n","\n","def difference_with_repetition(list1, list2):\n","    counter1 = Counter(list1)\n","    counter2 = Counter(list2)\n","\n","    difference_counter = counter1 - counter2\n","\n","    difference_list = list(difference_counter.elements())\n","\n","    return \" \".join(difference_list)\n","\n","def common_and_uncommon_parts(s1, s2):\n","    tokens1 = s1.split()\n","    tokens2 = s2.split()\n","    lengths = [[0 for j in range(len(tokens2)+1)] for i in range(len(tokens1)+1)]\n","    for i, x in enumerate(tokens1):\n","        for j, y in enumerate(tokens2):\n","            if x == y:\n","                lengths[i+1][j+1] = lengths[i][j] + 1\n","            else:\n","                lengths[i+1][j+1] = max(lengths[i+1][j], lengths[i][j+1])\n","    common = []\n","    x, y = len(tokens1), len(tokens2)\n","    while x != 0 and y != 0:\n","        if lengths[x][y] == lengths[x-1][y]:\n","            x -= 1\n","        elif lengths[x][y] == lengths[x][y-1]:\n","            y -= 1\n","        else:\n","            assert tokens1[x-1] == tokens2[y-1]\n","            common.insert(0, tokens1[x-1])\n","            x -= 1\n","            y -= 1\n","    common = ' '.join(common)\n","    uncommon1 = difference_with_repetition(tokens1, common.split())\n","    uncommon2 = difference_with_repetition(tokens2, common.split())\n","    return common, uncommon1, uncommon2\n","\n","crows_data = read_crows_data(CFG.crows_data)\n","\n","if CFG.topic=='race':\n","    topic = 'race-color'\n","else:\n","    topic = CFG.topic\n","topic_crows_data = crows_data[crows_data['bias_type'] == topic].reset_index(drop=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"10lwdMehSvc1","executionInfo":{"status":"ok","timestamp":1726152160399,"user_tz":-330,"elapsed":6807,"user":{"displayName":"Aishik Rakshit","userId":"15122983906308089605"}},"outputId":"92a2c254-64f3-427f-e801-2f8611c6db2a"},"outputs":[{"output_type":"stream","name":"stdout","text":["====================================================================================================\n","Total examples: 262\n","Metric score: 23.66\n","Stereotype score: 42.5\n","Anti-stereotype score: 59.57\n","Num. neutral: 135 51.53\n","====================================================================================================\n","\n","====================================================================================================\n","Total examples: 262\n","Metric score: 49.24\n","Stereotype score: 62.82\n","Anti-stereotype score: 30.39\n","Num. neutral: 4 1.53\n","====================================================================================================\n","\n","Crows Results\n","Soft-Debiased CMS: 23.66\n","DSD CMS: 49.24\n"]}],"source":["def get_crows_score(word_vectors):\n","    df_score = pd.DataFrame(columns=['sent_more', 'sent_less',\n","                                        'sent_more_score', 'sent_less_score',\n","                                        'score', 'stereo_antistereo', 'bias_type'])\n","\n","\n","    total_stereo, total_antistereo = 0, 0\n","    stereo_score, antistereo_score = 0, 0\n","\n","    N = 0\n","    neutral = 0\n","    total = len(topic_crows_data.index)\n","    for row in topic_crows_data.itertuples():\n","        N += 1\n","        sent1 = re.sub(f\"[{re.escape(string.punctuation)}]\", \"\", contractions.fix(row.sent1.lower()).replace('\\'s', ' is'))\n","        sent2 = re.sub(f\"[{re.escape(string.punctuation)}]\", \"\", contractions.fix(row.sent2.lower()).replace('\\'s', ' is'))\n","        direction = row.direction\n","        bias = row.bias_type\n","\n","        common_sequence, remainder1, remainder2 = common_and_uncommon_parts(sent1, sent2)\n","        remainder1 = replace_words(remainder1)\n","        remainder2 = replace_words(remainder2)\n","\n","        pair_score = 0\n","        context_vec = avg_feature_vector(common_sequence, word_vectors, num_features=CFG.embedding_dim)\n","        more_vec = avg_feature_vector(remainder1, word_vectors, num_features=CFG.embedding_dim)\n","        less_vec = avg_feature_vector(remainder2, word_vectors, num_features=CFG.embedding_dim)\n","\n","        more_vec = more_vec/np.linalg.norm(more_vec)\n","        less_vec = less_vec/np.linalg.norm(less_vec)\n","        context_vec = context_vec/np.linalg.norm(context_vec)\n","\n","        # Calculate cosine similarity\n","        more_score = spatial.distance.cosine(context_vec, more_vec)\n","        less_score = spatial.distance.cosine(context_vec, less_vec)\n","\n","        if more_score == less_score:\n","\n","            neutral += 1\n","        else:\n","            if direction == 'stereo':\n","                total_stereo += 1\n","                if more_score > less_score:\n","                    stereo_score += 1\n","                    pair_score = 1\n","            elif direction == 'antistereo':\n","                total_antistereo += 1\n","                if less_score > more_score:\n","                    antistereo_score += 1\n","                    pair_score = 1\n","\n","        sent_more, sent_less = '', ''\n","        if direction == 'stereo':\n","            sent_more = sent1\n","            sent_less = sent2\n","            sent_more_score = more_score\n","            sent_less_score = less_score\n","        else:\n","            sent_more = sent2\n","            sent_less =sent1\n","            sent_more_score = less_score\n","            sent_less_score = more_score\n","\n","    df_score = df_score._append({'sent_more': sent_more,\n","                                'sent_less': sent_less,\n","                                'sent_more_score': sent_more_score,\n","                                'sent_less_score': sent_less_score,\n","                                'score': pair_score,\n","                                'stereo_antistereo': direction,\n","                                'bias_type': bias\n","                                }, ignore_index=True)\n","\n","    print('=' * 100)\n","    print('Total examples:', N)\n","    print('Metric score:', round((stereo_score + antistereo_score) / N * 100, 2))\n","    print('Stereotype score:', round(stereo_score  / total_stereo * 100, 2))\n","    if antistereo_score != 0:\n","        print('Anti-stereotype score:', round(antistereo_score  / total_antistereo * 100, 2))\n","    print(\"Num. neutral:\", neutral, round(neutral / N * 100, 2))\n","    print('=' * 100)\n","    print()\n","    return round((stereo_score + antistereo_score) / N * 100, 2), round(stereo_score  / total_stereo * 100, 2), round(antistereo_score  / total_antistereo * 100, 2)\n","\n","results['Soft-Debiased CMS'], results['Soft-Debiased CSS'], results['Soft-Debiased CAS'] = get_crows_score(soft_word_vectors)\n","results['DSD CMS'], results['DSD CSS'], results['DSD CAS'] = get_crows_score(DSD_soft_word_vectors)\n","\n","print(\"Crows Results\")\n","print(f\"Soft-Debiased CMS: {results['Soft-Debiased CMS']}\")\n","print(f\"DSD CMS: {results['DSD CMS']}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3YQ1tdr-vlAK"},"outputs":[],"source":["def save_results(results, filename):\n","    file_exists = os.path.isfile(filename)\n","\n","    with open(filename, 'a') as csvfile:\n","        writer = csv.DictWriter(csvfile, fieldnames=results.keys())\n","\n","        if not file_exists:\n","            writer.writeheader()  # file doesn't exist yet, write a header\n","\n","        writer.writerow(results)\n","\n","save_results(results, CFG.results_filename)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o_ParyazTazc"},"outputs":[],"source":["def DSD_Debias(Transform, new_word_dict):\n","    new_debiased_word_dict = {}\n","    for word,w_ in new_word_dict.items():\n","        w_ = torch.tensor(w_).float().to(CFG.device)\n","        transformedVec = Transform(w_.view(1, -1))\n","        new_debiased_word_dict[word] = ( transformedVec / transformedVec.norm(p=2) ).detach().cpu().numpy().flatten()\n","    return new_debiased_word_dict\n","\n","def Soft_Debias(debias_matrix, word_vectors):\n","    new_debiased_word_dict = {}\n","    for word,w_ in word_vectors.items():\n","        w_ = torch.tensor(w_).float()\n","        transformedVec = torch.mm(debias_matrix, w_.view(-1, 1))\n","        new_debiased_word_dict[word] = ( transformedVec / transformedVec.norm(p=2) ).detach().numpy().flatten()\n","    return new_debiased_word_dict"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cyse_QA8jwST","executionInfo":{"status":"ok","timestamp":1726152196027,"user_tz":-330,"elapsed":35629,"user":{"displayName":"Aishik Rakshit","userId":"15122983906308089605"}},"colab":{"base_uri":"https://localhost:8080/","height":241,"referenced_widgets":["5f7201d2ac834ad69b49fea417287133","9ef2fa7fe90346ba95333ae83de07b05","43badb0a04a5473e96e09e951ec5af95","2ba6876f5eea439680e469c2dd006f9c","747f0a51da1240aba543ed4826cba403","5c9bd5ae2450477c86553ef09f6a8a64","ea12cdba34c444b5a3ca7256ccedfc86","2d68b01b9be54882906fe07a1551288c","2d311d0705f540a698bfc69b66316283","368c33ee46a04040a49caa2c2cb36921","79a2d60e4b9a4f24942d84ff9a0bd5bc","ca67c328697c48a0b07a19cb40b69b88","400f2b73230c4b08bac2f0a0029dce9d","c84ad826dc6f45a8b8570eba55924110","09db358e132e433088dacc19c4389e03","bd21efa1d3984f76b9d7110ed88a0896","ca7e3dc8990545368efaa81e0a5046bd","f219a948d733437caca190cb9fd7cd0f","03ecea16949f4a76a20607e425a4c477","8546978d108e4f42b0f29537d3f190f9","433dfb0ee21546859555511028459ec3","fe313e4e92bd48b58fa6c1892d41c023","36f537d725a444e2b72452cffc5b020b","d37f67dc74724bd8a6759c69d94beacf","4116d13c03ab4408be457ac7ccc162b8","fbaa8dabdf264785b2dacfe8b9a5c3bd","c41def39aa4c49778b5131967eed313c","c0109c0e34e84a33bafb2e16233e6122","a483c130bf644e12bf318c96f009a51d","56ab97f1dd9a45c198f41b8d6f1005be","f0cd88aa7cf044328646aba83396e824","c40fceda3f594e8a8f76d238511b0100","fb486617a0ec4389a8f32ca14e957630","c21bcec83d3744639d4afcfe201cabf4","484e7a0e6c9c474fb5ab44fff54ce2e2","4e6980734e1049ca8431620290eb8396","05794156f4fe4c32bb6398113ce8986f","545d8a6b56ac4d0eacdad4ab79824399","f247bf1907704b4caa620d7ca2bb6b36","ab6f1a25da7a4475a8a743786b217705","9f655f10936f4d0ba4b2ae8d2912cb42","2feecf9d00754e89920eb70eeb04592c","992c7d6d437f437297983ffd0f0bc3c7","260aef7ec4344a128e2e46f7269afd92","25b6f76ba518463fb3e6f722dc24249a","a49941ea16a540719dac5c42523fc390","9d8dcebe0f404d4fbb8196bc160abfe2","355b3bebcd0141b8bd60be8d7f425c46","d3f2a92350954318af303d87a68a3437","688ef6e43cae4bbab3fece6d16b3f13e","3b2551f2d7d840c4b8bcb50a551d2321","751c2154c6f544af9059bf1c6d522f9e","897ec2dd67e4442187a90bb053ab3a94","3bf459f1f2404e05b06bb7879892de96","10bf61152ecb4ecd89b777decbf883ce","d7d486bfbacf4a54b631916fcd16751c","d6083f65ef5b42efa05f25ff7cc5f4b5","81cda875f06f4d2f826741595088f11a","3d86606bbbcb48d3ae0e2c683a9074fb","aa39950989014445b42fcfdf89da7a5d","5b4268a87e9c48659140d0895a2724a4","875d2ddface74faebeed80b50319d741","6b6d97b4c04d4f72a1a83bb13da2f313","ce12e7fe2a184875bcb027a61700dbbf","574d9c23052b4197adb9bf3762353368","03491f6d3fe143558c91b73d5aa237d9","37ecf2a0df724879a35279d7f1e3922e","b7820465ec53409d85276b67c4f54214","731be271ca5244379c91cf1b7ac71046","00176395e029495abdb9514e31c7c480","ef7723121ec74503a945678718531ac1","07e353dbcfdb4be68be68cfd1d8de407","3bb50b34ad7f4d639a39aebdc67392e0","a8f91f32b27d482ab8047deeb941e0ba","58932168ab164fd9a695583a00ca5d17","9def10b9b1224a2dbe36ae6c7ace2bd0","7b34c61b3a754f49accfd61437d4ccde"]},"outputId":"ffecbe02-aaab-44be-9275-14adad670913"},"outputs":[{"output_type":"display_data","data":{"text/plain":["README.md:   0%|          | 0.00/35.3k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f7201d2ac834ad69b49fea417287133"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["train-00000-of-00001.parquet:   0%|          | 0.00/502k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca67c328697c48a0b07a19cb40b69b88"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["validation-00000-of-00001.parquet:   0%|          | 0.00/151k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36f537d725a444e2b72452cffc5b020b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["test-00000-of-00001.parquet:   0%|          | 0.00/114k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c21bcec83d3744639d4afcfe201cabf4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating train split:   0%|          | 0/5749 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25b6f76ba518463fb3e6f722dc24249a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating validation split:   0%|          | 0/1500 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d7d486bfbacf4a54b631916fcd16751c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating test split:   0%|          | 0/1379 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"37ecf2a0df724879a35279d7f1e3922e"}},"metadata":{}}],"source":["stsb_dataset = load_dataset(\"glue\", \"stsb\")\n","sentence_pairs = [(row[\"sentence1\"], row[\"sentence2\"]) for row in stsb_dataset[\"train\"]]\n","similarity_scores = [row[\"label\"] for row in stsb_dataset[\"train\"]]\n","\n","stop_words = set(stopwords.words('english'))\n","\n","if not os.path.isfile(CFG.stsb_word_vectors):\n","    def preprocess_text(text):\n","        tokens = nltk.word_tokenize(text.lower())\n","        filtered_tokens = [word for word in tokens if word.isalpha() and word not in stop_words]\n","        return filtered_tokens\n","\n","    sentences = []\n","    for  pair in sentence_pairs:\n","        sentence1, sentence2 = pair[0], pair[1]\n","\n","        sentences.append(sentence1)\n","        sentences.append(sentence2)\n","\n","    sentences = [preprocess_text(sentence) for sentence in sentences]\n","\n","    stsb_words = set()\n","    for sentence in sentences:\n","        for word in sentence:\n","            stsb_words.add(word)\n","\n","    stsb_words = list(stsb_words)\n","    stsb_word_embeddings = get_word_embeddings(stsb_words, lm_model)\n","    stsb_word_dict = {word: embedding for (word, embedding) in zip(stsb_words, stsb_word_embeddings)}\n","    pickle.dump(stsb_word_dict, open(CFG.stsb_word_vectors, \"wb\"))\n","else:\n","    stsb_word_dict = pickle.load(open(CFG.stsb_word_vectors, \"rb\"))\n","stsb_soft_debiased_word_dict = Soft_Debias(debias_matrix, stsb_word_dict)\n","stsb_DSD_word_dict = DSD_Debias(debias_model, stsb_word_dict)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gOqFWdXflMJz","executionInfo":{"status":"ok","timestamp":1726152426017,"user_tz":-330,"elapsed":229998,"user":{"displayName":"Aishik Rakshit","userId":"15122983906308089605"}},"outputId":"d3968393-fa49-49a8-fef1-84400152a675"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 9, Loss: 4.01935701072216\n","Epoch 19, Loss: 3.3803985375497074\n","Epoch 29, Loss: 2.896292200518979\n","Epoch 39, Loss: 2.5527993506855435\n","Epoch 49, Loss: 2.325289491150114\n","Epoch 59, Loss: 2.198770129846202\n","Epoch 69, Loss: 2.147483723858992\n","Epoch 79, Loss: 2.1336673158738346\n","Epoch 89, Loss: 2.1302604799469314\n","Epoch 99, Loss: 2.12977232121759\n","Validation loss: 2.203318807813856\n","PCC: 0.02225879497708774, SRCC: -0.0669417932888278\n","Epoch 9, Loss: 7.265724748373032\n","Epoch 19, Loss: 6.1189716590775385\n","Epoch 29, Loss: 5.147807990511258\n","Epoch 39, Loss: 4.321952142649227\n","Epoch 49, Loss: 3.650464192032814\n","Epoch 59, Loss: 3.111468012962076\n","Epoch 69, Loss: 2.707118002076944\n","Epoch 79, Loss: 2.4294080254104404\n","Epoch 89, Loss: 2.2616645875904293\n","Epoch 99, Loss: 2.1788069299525685\n","Validation loss: 2.191667358080546\n","PCC: -0.023702759974915333, SRCC: -0.040569987747178696\n","Epoch 9, Loss: 7.809370166725582\n","Epoch 19, Loss: 6.5957386328114405\n","Epoch 29, Loss: 5.554516519109408\n","Epoch 39, Loss: 4.668119521604644\n","Epoch 49, Loss: 3.9287168780962625\n","Epoch 59, Loss: 3.3325155874093375\n","Epoch 69, Loss: 2.8726252482997046\n","Epoch 79, Loss: 2.5432469894488654\n","Epoch 89, Loss: 2.3282841510242887\n","Epoch 99, Loss: 2.2114063700040183\n","Validation loss: 2.2693269352118173\n","PCC: 0.028618714077415702, SRCC: 0.003456455520309411\n"]}],"source":["class STSBModel(nn.Module):\n","    def __init__(self, input_dim):\n","        super(STSBModel, self).__init__()\n","        self.fc1 = nn.LazyLinear(input_dim//2)\n","        self.fc1_1 = nn.LazyLinear(input_dim//4)\n","        self.fc2 = nn.LazyLinear(input_dim//2)\n","        self.fc2_1 = nn.LazyLinear(input_dim//4)\n","        self.fc3 = nn.LazyLinear(1)\n","\n","    def forward(self, x1, x2):\n","        x1 = self.fc1(x1)\n","        x1 = self.fc1_1(x1)\n","        x2 = self.fc2(x2)\n","        x2 = self.fc2_1(x2)\n","        x = F.cosine_similarity(x1, x2).view(-1,1)\n","        x = self.fc3(x)\n","        return x\n","\n","class SentencePairDataset(Dataset):\n","    def __init__(self, embeddings, scores):\n","        self.embeddings = embeddings\n","        self.scores = scores\n","\n","    def __len__(self):\n","        return len(self.embeddings)\n","\n","    def __getitem__(self, idx):\n","        return self.embeddings[idx], self.scores[idx]\n","\n","def get_stsb_score(word_embeddings):\n","\n","    # Convert the sentence pairs to embeddings\n","    embeddings = [(avg_feature_vector(s1, word_embeddings, num_features=CFG.embedding_dim), avg_feature_vector(s2, word_embeddings, num_features=CFG.embedding_dim)) for s1, s2 in sentence_pairs]\n","\n","    # Split the data into a training set and a validation set\n","    train_embeddings, val_embeddings, train_scores, val_scores = train_test_split(embeddings, similarity_scores, test_size=0.2)\n","\n","    # Create DataLoaders\n","    train_dataloader = DataLoader(SentencePairDataset(train_embeddings, train_scores), batch_size=32, shuffle=True)\n","    val_dataloader = DataLoader(SentencePairDataset(val_embeddings, val_scores), batch_size=32)\n","\n","    # Instantiate the model and define the loss and optimizer\n","    model = STSBModel(CFG.embedding_dim).to(CFG.device)\n","    # Choose a loss function and an optimizer\n","    loss_fn = nn.MSELoss()\n","    optimizer = optim.Adam(model.parameters(), lr = 1e-4)\n","\n","    # Training loop\n","    for epoch in range(100):\n","        losses = []\n","        for embeddings, scores in train_dataloader:\n","            embeddings1 = torch.tensor(embeddings[0], dtype=torch.float32).to(CFG.device)\n","            embeddings2 = torch.tensor(embeddings[1], dtype=torch.float32).to(CFG.device)\n","            scores = torch.tensor(scores, dtype=torch.float32).to(CFG.device)\n","            outputs = model(embeddings1, embeddings2)\n","            loss = loss_fn(outputs, scores)\n","            losses.append(loss.item())\n","            loss.backward()\n","            optimizer.step()\n","            optimizer.zero_grad()\n","\n","        if((epoch+1)%10==0):\n","            print(f\"Epoch {epoch}, Loss: {np.mean(losses)}\")\n","\n","    # Evaluation\n","    model.eval()\n","    total_loss, total_count = 0, 0\n","    y_true, y_pred = [], []\n","    with torch.no_grad():\n","        for embeddings, scores in val_dataloader:\n","            embeddings1 = torch.tensor(embeddings[0], dtype=torch.float32).to(CFG.device)\n","            embeddings2 = torch.tensor(embeddings[1], dtype=torch.float32).to(CFG.device)\n","            scores = torch.tensor(scores, dtype=torch.float32).to(CFG.device)\n","            outputs = model(embeddings1, embeddings2)\n","            loss = loss_fn(outputs, scores)\n","            total_loss += loss.item()\n","            total_count += 1\n","            outputs = [item for item_l in outputs.cpu().tolist() for item in item_l]\n","            y_true.extend(scores.cpu().tolist())\n","            y_pred.extend(outputs)\n","    avg_loss = total_loss / total_count\n","    print(f\"Validation loss: {avg_loss}\")\n","    # Compute evaluation metrics\n","    pcc = pearsonr(y_true, y_pred)[0]\n","    srcc = spearmanr(y_true, y_pred)[0]\n","    print(f\"PCC: {pcc}, SRCC: {srcc}\")\n","    return (pcc, srcc)\n","\n","\n","downstream_results['STSB Biased PCC'], downstream_results['STSB Biased SRCC'] = get_stsb_score(stsb_word_dict)\n","downstream_results['STSB Soft-Debiased PCC'], downstream_results['STSB Soft-Debiased SRCC'] = get_stsb_score(stsb_soft_debiased_word_dict)\n","downstream_results['STSB DSD PCC'], downstream_results['STSB DSD CC'] = get_stsb_score(stsb_DSD_word_dict)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"8UUmmaUDx_-X","executionInfo":{"status":"ok","timestamp":1726152492544,"user_tz":-330,"elapsed":66543,"user":{"displayName":"Aishik Rakshit","userId":"15122983906308089605"}},"outputId":"6f142af0-1f16-4c2c-e354-6df6e7e0de8b"},"outputs":[{"output_type":"display_data","data":{"text/plain":["                                               words  \\\n","0  [EU, rejects, German, call, to, boycott, Briti...   \n","1                                 [Peter, Blackburn]   \n","2                             [BRUSSELS, 1996-08-22]   \n","3  [The, European, Commission, said, on, Thursday...   \n","4  [Germany, 's, representative, to, the, Europea...   \n","\n","                                                tags  \n","0  [B-organisation, O, B-misc, O, O, O, B-misc, O...  \n","1                               [B-person, I-person]  \n","2                                    [B-location, O]  \n","3  [O, B-organisation, I-organisation, O, O, O, O...  \n","4  [B-location, O, O, O, O, B-organisation, I-org...  "],"text/html":["\n","  <div id=\"df-f6f0863b-45c9-4c15-9c45-85b125434c6e\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>words</th>\n","      <th>tags</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>[EU, rejects, German, call, to, boycott, Briti...</td>\n","      <td>[B-organisation, O, B-misc, O, O, O, B-misc, O...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>[Peter, Blackburn]</td>\n","      <td>[B-person, I-person]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>[BRUSSELS, 1996-08-22]</td>\n","      <td>[B-location, O]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>[The, European, Commission, said, on, Thursday...</td>\n","      <td>[O, B-organisation, I-organisation, O, O, O, O...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>[Germany, 's, representative, to, the, Europea...</td>\n","      <td>[B-location, O, O, O, O, B-organisation, I-org...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f6f0863b-45c9-4c15-9c45-85b125434c6e')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-f6f0863b-45c9-4c15-9c45-85b125434c6e button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-f6f0863b-45c9-4c15-9c45-85b125434c6e');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-fb1b9ea4-9dc7-4130-9ccf-f73b6d0c1c50\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fb1b9ea4-9dc7-4130-9ccf-f73b6d0c1c50')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-fb1b9ea4-9dc7-4130-9ccf-f73b6d0c1c50 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"cross_ner_DSD_word_dict = DSD_Debias(debias_model, cross_ner_word_dict)\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"words\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tags\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}}],"source":["def preprocess_text(text):\n","    tokens = nltk.word_tokenize(text.lower())\n","    filtered_tokens = [word for word in tokens if word.isalpha() and word not in stop_words]\n","    return filtered_tokens\n","\n","def load_data_cross_ner(file_path):\n","    with open(file_path, 'r') as f:\n","        lines = f.readlines()\n","\n","    words, tags = [], []\n","    sentence_words, sentence_tags = [], []\n","\n","    for line in lines:\n","        line = line.strip()\n","        if len(line) == 0 or line.startswith(\"-DOCSTART-\"):\n","            if len(sentence_words) > 0:\n","                words.append(sentence_words)\n","                tags.append(sentence_tags)\n","                sentence_words, sentence_tags = [], []\n","        else:\n","            tokens = line.split('\\t')\n","            sentence_words.append(tokens[0])\n","            sentence_tags.append(tokens[-1])\n","\n","    return pd.DataFrame({\"words\": words, \"tags\": tags})\n","\n","data = load_data_cross_ner(CFG.cross_ner_data)\n","display(data.head())\n","\n","sentences, sentence_tags = [], []\n","for _,tagged_sentence in data.iterrows():\n","    sentence, tags = tagged_sentence['words'], tagged_sentence['tags']\n","\n","    sentences.append(\" \".join(sentence))\n","    sentence_tags.append(np.array(tags))\n","\n","sentences = [preprocess_text(sentence) for sentence in sentences]\n","\n","if not os.path.isfile(CFG.cross_ner_word_vectors):\n","    words_ = set()\n","    for sentence in sentences:\n","        for word in sentence:\n","            words_.add(word)\n","    words_ = list(words_)\n","    cross_ner_word_embeddings = get_word_embeddings(words_, lm_model)\n","    cross_ner_word_dict = {word: embedding for (word, embedding) in zip(words_, cross_ner_word_embeddings)}\n","    pickle.dump(cross_ner_word_dict, open(CFG.cross_ner_word_vectors, \"wb\"))\n","else:\n","    cross_ner_word_dict = pickle.load(open(CFG.cross_ner_word_vectors, \"rb\"))\n","\n","cross_ner_soft_debiased_word_dict = Soft_Debias(debias_matrix, cross_ner_word_dict)\n","cross_ner_DSD_word_dict = DSD_Debias(debias_model, cross_ner_word_dict)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JB0a-JLe3Kd2","executionInfo":{"status":"ok","timestamp":1726153095936,"user_tz":-330,"elapsed":603399,"user":{"displayName":"Aishik Rakshit","userId":"15122983906308089605"}},"outputId":"41fcdd7a-205a-4b89-ca49-e5f43801699f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loss @ Epoch #9: 0.07720741629600525\n","Loss @ Epoch #9: 0.10245310515165329\n","Loss @ Epoch #9: 0.03283114731311798\n"]}],"source":["class BiLSTM(nn.Module):\n","    def __init__(self, num_classes):\n","        super(BiLSTM, self).__init__()\n","        self.lstm = nn.LSTM(embedding_dim, embedding_dim//2, bidirectional=True, batch_first=True)\n","        self.fc = nn.LazyLinear(num_classes)\n","\n","    def forward(self, x):\n","        x, _ = self.lstm(x)\n","        x = self.fc(x)\n","        return x\n","\n","def get_cross_ner_score(word_embedding_dict, sentences, sentence_tags):\n","    X = [[word_embedding_dict[word] if word in word_embedding_dict else word_embedding_dict['<UNK>'] for word in sentence] for sentence in sentences]\n","    y = [[tag for tag in tags] for tags in sentence_tags]\n","    tags = []\n","    for tagss in y:\n","        for tag in tagss:\n","            tags.append(tag)\n","\n","    tags = list(set(tags))\n","\n","    # Encode the labels\n","    le = LabelEncoder()\n","    le.fit(tags)\n","    y = [le.transform(tags) for tags in y]\n","    X = torch.tensor(pad_sequences(maxlen=100, sequences=X, padding=\"post\", dtype='float32'))\n","    y = torch.tensor(pad_sequences(maxlen=100, sequences=y, padding=\"post\", value=le.transform([\"O\"])))\n","\n","    # Split the data into training and test sets\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n","\n","    # Create DataLoaders\n","    train_data = TensorDataset(X_train, y_train)\n","    train_loader = DataLoader(train_data, batch_size=32)\n","\n","    test_data = TensorDataset(X_test, y_test)\n","    test_loader = DataLoader(test_data, batch_size=32)\n","\n","    model_lstm = BiLSTM(len(le.classes_)).to(CFG.device)\n","    criterion = nn.CrossEntropyLoss()  # Set ignore_index to ignore the padding label\n","    optimizer = optim.Adam(model_lstm.parameters())\n","\n","    # Train the model\n","    for epoch in range(10):\n","        for i, (sentences, labels) in enumerate(train_loader):\n","            optimizer.zero_grad()\n","            # print(sentences.shape, labels.shape)\n","            outputs = model_lstm(sentences.to(CFG.device))\n","            loss = criterion(outputs.view(-1, len(le.classes_)), labels.long().view(-1).to(CFG.device))\n","            loss.backward()\n","            optimizer.step()\n","        if (epoch+1)%10==0:\n","            print(\"Loss @ Epoch #\" + str(epoch) + \":\", loss.item())\n","    # Make predictions on the test set and evaluate the model_lstm\n","    with torch.no_grad():\n","        all_preds, all_labels = [], []\n","        for sentences, labels in test_loader:\n","            outputs = model_lstm(sentences.to(CFG.device))\n","            _, predicted = torch.max(outputs, 2)\n","            all_preds.extend(predicted.view(-1).detach().cpu().tolist())\n","            all_labels.extend(labels.view(-1).tolist())\n","\n","    return classification_report(all_labels, all_preds, target_names=le.classes_, output_dict = True)['macro avg']['f1-score']\n","\n","downstream_results['Cross-NER Biased F1'] = get_cross_ner_score(cross_ner_word_dict, sentences, sentence_tags)\n","downstream_results['Cross-NER Soft-Debiased F1'] = get_cross_ner_score(cross_ner_soft_debiased_word_dict, sentences, sentence_tags)\n","downstream_results['Cross-NER DSD F1'] = get_cross_ner_score(cross_ner_DSD_word_dict, sentences, sentence_tags)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gl_64aqFETdU"},"outputs":[],"source":["stop_words = set(stopwords.words('english'))\n","df = pd.read_csv(CFG.stanford_sentiment_treebank_data)\n","def preprocess_text(text):\n","    tokens = nltk.word_tokenize(text.lower())\n","    filtered_tokens = [word for word in tokens if word not in stop_words]\n","    return filtered_tokens\n","\n","label_map = {'positive': 1, 'negative': 0}\n","df['processed_sentence'] = df['sentence'].apply(preprocess_text)\n","df['hard_label'] = df['label'].apply(lambda x: int(np.round(x+0.0001)))\n","# Split data into train and test sets\n","X_train, X_test, y_train, y_test = train_test_split(df['processed_sentence'], df['hard_label'], test_size=0.2, random_state=42)\n","\n","# Train a Word2Vec model on unlabeled data\n","if not os.path.isfile(CFG.sst_word_vectors):\n","    sentences = [sentence for sentence in df['processed_sentence']]\n","    words_ = set()\n","    for sentence in sentences:\n","        for word in sentence:\n","            words_.add(word)\n","    sst_words = list(words_)\n","\n","    sst_word_embeddings = get_word_embeddings(sst_words, lm_model)\n","    sst_word_dict = {word: embedding for (word, embedding) in zip(sst_words, sst_word_embeddings)}\n","    pickle.dump(sst_word_dict, open(CFG.sst_word_vectors, \"wb\"))\n","else:\n","    sst_word_dict = pickle.load(open(CFG.sst_word_vectors, \"rb\"))\n","\n","sst_soft_debiased_word_dict = Soft_Debias(debias_matrix, sst_word_dict)\n","sst_debiased_word_dict = DSD_Debias(debias_model, sst_word_dict)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8m5gg-awEOxf","executionInfo":{"status":"ok","timestamp":1726153220145,"user_tz":-330,"elapsed":79547,"user":{"displayName":"Aishik Rakshit","userId":"15122983906308089605"}},"outputId":"5ecb8c31-71a3-4025-9138-0bcba79739c8"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 6835/6835 [00:00<00:00, 13264.71it/s]\n","100%|██████████| 1709/1709 [00:00<00:00, 13377.32it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy: 0.69\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 6835/6835 [00:00<00:00, 13360.66it/s]\n","100%|██████████| 1709/1709 [00:00<00:00, 13026.21it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy: 0.68\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 6835/6835 [00:00<00:00, 13893.90it/s]\n","100%|██████████| 1709/1709 [00:00<00:00, 13540.44it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy: 0.69\n"]}],"source":["def get_sst_score(cls_word_dict):\n","# Vectorize labeled reviews\n","    X_train_vec = np.array([np.mean([cls_word_dict[word] for word in review], axis=0) for review in tqdm(X_train)])\n","    X_test_vec = np.array([np.mean([cls_word_dict[word] for word in review], axis=0) for review in tqdm(X_test)])\n","\n","    # Train an XGBoost classifier\n","    xgb_model = XGBClassifier(n_estimators=150, max_depth=3, learning_rate=0.05)\n","    xgb_model.fit(X_train_vec, y_train)\n","\n","    # Make predictions\n","    y_pred = xgb_model.predict(X_test_vec)\n","\n","    # Evaluate the model\n","    accuracy = accuracy_score(y_test, y_pred)\n","    print(f\"Accuracy: {accuracy:.2f}\")\n","    return accuracy\n","\n","downstream_results['SST Biased Accuracy'] = get_sst_score(sst_word_dict)\n","downstream_results['SST Soft-Debiased Accuracy'] = get_sst_score(sst_soft_debiased_word_dict)\n","downstream_results['SST DSD Accuracy'] = get_sst_score(sst_debiased_word_dict)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D82ifSaTW7vA"},"outputs":[],"source":["splits = {'train': 'train.jsonl', 'validation': 'validation.jsonl', 'test': 'test.jsonl'}\n","mrpc_df = pd.read_json(\"hf://datasets/SetFit/mrpc/\" + splits[\"train\"], lines=True)\n","\n","sentence_pairs = [(row[\"text1\"], row[\"text2\"]) for _, row in mrpc_df.iterrows()]\n","similarity_scores = [row[\"label\"] for _,row in mrpc_df.iterrows()]\n","\n","stop_words = set(stopwords.words('english'))\n","\n","if not os.path.isfile(CFG.mrpc_word_vectors):\n","    def preprocess_text(text):\n","        tokens = nltk.word_tokenize(text.lower())\n","        filtered_tokens = [word for word in tokens if word.isalpha() and word not in stop_words]\n","        return filtered_tokens\n","\n","    sentences = []\n","    for  pair in sentence_pairs:\n","        sentence1, sentence2 = pair[0], pair[1]\n","\n","        sentences.append(sentence1)\n","        sentences.append(sentence2)\n","\n","    sentences = [preprocess_text(sentence) for sentence in sentences]\n","\n","    mrpc_words = set()\n","    for sentence in sentences:\n","        for word in sentence:\n","            mrpc_words.add(word)\n","\n","    mrpc_words = list(mrpc_words)\n","    mrpc_word_embeddings = get_word_embeddings(mrpc_words, lm_model)\n","    mrpc_word_dict = {word: embedding for (word, embedding) in zip(mrpc_words, mrpc_word_embeddings)}\n","    pickle.dump(mrpc_word_dict, open(CFG.mrpc_word_vectors, \"wb\"))\n","else:\n","    mrpc_word_dict = pickle.load(open(CFG.mrpc_word_vectors, \"rb\"))\n","mrpc_soft_debiased_word_dict = Soft_Debias(debias_matrix, mrpc_word_dict)\n","mrpc_DSD_word_dict = DSD_Debias(debias_model, mrpc_word_dict)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m5oi2EnW4ffS","executionInfo":{"status":"ok","timestamp":1726153487225,"user_tz":-330,"elapsed":220623,"user":{"displayName":"Aishik Rakshit","userId":"15122983906308089605"}},"outputId":"5ef60442-6f0f-43f0-9b2e-d554140acb4c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 9, Loss: 0.49724398164645484\n","Epoch 19, Loss: 0.47793393031410547\n","Epoch 29, Loss: 0.45976818450119183\n","Epoch 39, Loss: 0.4427742507794629\n","Epoch 49, Loss: 0.4269089131899502\n","Epoch 59, Loss: 0.4113661669518637\n","Epoch 69, Loss: 0.3963499694414761\n","Epoch 79, Loss: 0.38230599884105765\n","Epoch 89, Loss: 0.36850231205639633\n","Epoch 99, Loss: 0.35562589440656744\n","Validation loss: 0.36419143884078314\n","F1 Score: 0.23621227887617066\n","Epoch 9, Loss: 0.45456014767937036\n","Epoch 19, Loss: 0.4382284571943076\n","Epoch 29, Loss: 0.4217740433371585\n","Epoch 39, Loss: 0.40615589689949283\n","Epoch 49, Loss: 0.39170484989881516\n","Epoch 59, Loss: 0.37747375472732214\n","Epoch 69, Loss: 0.36422661789085553\n","Epoch 79, Loss: 0.35135092294734455\n","Epoch 89, Loss: 0.3391324936047844\n","Epoch 99, Loss: 0.3276926777932955\n","Validation loss: 0.32154051117275073\n","F1 Score: 0.25406504065040647\n","Epoch 9, Loss: 0.7213081885939059\n","Epoch 19, Loss: 0.6942482454621274\n","Epoch 29, Loss: 0.669869248309861\n","Epoch 39, Loss: 0.6462030022040658\n","Epoch 49, Loss: 0.6232863463785338\n","Epoch 59, Loss: 0.6009577256829842\n","Epoch 69, Loss: 0.5800956147520439\n","Epoch 79, Loss: 0.559203523332658\n","Epoch 89, Loss: 0.5387386258529581\n","Epoch 99, Loss: 0.5193028440294059\n","Validation loss: 0.528339463731517\n","F1 Score: 0.23937823834196892\n"]}],"source":["def get_mrpc_score(word_embeddings):\n","\n","    # Convert the sentence pairs to embeddings\n","    embeddings = [(avg_feature_vector(s1, word_embeddings, num_features=CFG.embedding_dim), avg_feature_vector(s2, word_embeddings, num_features=CFG.embedding_dim)) for s1, s2 in sentence_pairs]\n","\n","    # Split the data into a training set and a validation set\n","    train_embeddings, val_embeddings, train_scores, val_scores = train_test_split(embeddings, similarity_scores, test_size=0.2)\n","\n","    # Create DataLoaders\n","    train_dataloader = DataLoader(SentencePairDataset(train_embeddings, train_scores), batch_size=32, shuffle=True)\n","    val_dataloader = DataLoader(SentencePairDataset(val_embeddings, val_scores), batch_size=32)\n","\n","    # Instantiate the model and define the loss and optimizer\n","    model = STSBModel(CFG.embedding_dim).to(CFG.device)\n","    # Choose a loss function and an optimizer\n","    loss_fn = nn.MSELoss()\n","    optimizer = optim.Adam(model.parameters(), lr = 1e-5)\n","\n","    # Training loop\n","    for epoch in range(100):\n","        losses = []\n","        for embeddings, scores in train_dataloader:\n","            embeddings1 = torch.tensor(embeddings[0], dtype=torch.float32).to(CFG.device)\n","            embeddings2 = torch.tensor(embeddings[1], dtype=torch.float32).to(CFG.device)\n","            scores = torch.tensor(scores, dtype=torch.float32).to(CFG.device)\n","            outputs = model(embeddings1, embeddings2)\n","            loss = loss_fn(outputs, scores)\n","            losses.append(loss.item())\n","            loss.backward()\n","            optimizer.step()\n","            optimizer.zero_grad()\n","\n","        if((epoch+1)%10==0):\n","            print(f\"Epoch {epoch}, Loss: {np.mean(losses)}\")\n","\n","    # Evaluation\n","    model.eval()\n","    total_loss, total_count = 0, 0\n","    y_true, y_pred = [], []\n","    with torch.no_grad():\n","        for embeddings, scores in val_dataloader:\n","            embeddings1 = torch.tensor(embeddings[0], dtype=torch.float32).to(CFG.device)\n","            embeddings2 = torch.tensor(embeddings[1], dtype=torch.float32).to(CFG.device)\n","            scores = torch.tensor(scores, dtype=torch.float32).to(CFG.device)\n","            outputs = model(embeddings1, embeddings2)\n","            loss = loss_fn(outputs, scores)\n","            total_loss += loss.item()\n","            total_count += 1\n","            outputs = [item for item_l in outputs.cpu().tolist() for item in item_l]\n","            y_true.extend(scores.cpu().tolist())\n","            y_pred.extend(outputs)\n","    avg_loss = total_loss / total_count\n","    print(f\"Validation loss: {avg_loss}\")\n","    # Compute evaluation metrics\n","    y_pred = [round(pred) for pred in y_pred]\n","    f1 = f1_score(y_true, y_pred, average = \"macro\")\n","    print(f\"F1 Score: {f1}\")\n","    return f1\n","\n","downstream_results['MRPC Biased F1'] = get_mrpc_score(mrpc_word_dict)\n","downstream_results['MRPC Soft-Debiased F1'] = get_mrpc_score(mrpc_soft_debiased_word_dict)\n","downstream_results['MRPC DSD F1'] = get_mrpc_score(mrpc_DSD_word_dict)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Apwk8swDCWYv"},"outputs":[],"source":["splits = {'train': 'train.jsonl', 'validation': 'validation_matched.jsonl', 'test': 'test_matched.jsonl'}\n","mnli_df = pd.read_json(\"hf://datasets/SetFit/mnli/\" + splits[\"train\"], lines=True)\n","mnli_df = mnli_df.sample(frac=0.01,random_state=42 ).reset_index(drop=True)\n","sentence_pairs = [(row[\"text1\"], row[\"text2\"]) for _, row in mnli_df.iterrows()]\n","similarity_scores = [row[\"label\"] for _,row in mnli_df.iterrows()]\n","\n","stop_words = set(stopwords.words('english'))\n","\n","if not os.path.isfile(CFG.mnli_word_vectors):\n","    def preprocess_text(text):\n","        tokens = nltk.word_tokenize(text.lower())\n","        filtered_tokens = [word for word in tokens if word.isalpha() and word not in stop_words]\n","        return filtered_tokens\n","\n","    sentences = []\n","    for  pair in sentence_pairs:\n","        sentence1, sentence2 = pair[0], pair[1]\n","\n","        sentences.append(sentence1)\n","        sentences.append(sentence2)\n","\n","    sentences = [preprocess_text(sentence) for sentence in sentences]\n","\n","    mnli_words = set()\n","    for sentence in sentences:\n","        for word in sentence:\n","            mnli_words.add(word)\n","\n","    mnli_words = list(mnli_words)\n","    mnli_word_embeddings = get_word_embeddings(mnli_words, lm_model)\n","    mnli_word_dict = {word: embedding for (word, embedding) in zip(mnli_words, mnli_word_embeddings)}\n","    pickle.dump(mnli_word_dict, open(CFG.mnli_word_vectors, \"wb\"))\n","else:\n","    mnli_word_dict = pickle.load(open(CFG.mnli_word_vectors, \"rb\"))\n","mnli_soft_debiased_word_dict = Soft_Debias(debias_matrix, mnli_word_dict)\n","mnli_DSD_word_dict = DSD_Debias(debias_model, mnli_word_dict)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BiSLVNEyCrAC","executionInfo":{"status":"ok","timestamp":1726153749988,"user_tz":-330,"elapsed":205649,"user":{"displayName":"Aishik Rakshit","userId":"15122983906308089605"}},"outputId":"8ed52529-eab5-4348-d3de-f29a16e40ae2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 9, Loss: 0.6846752624319057\n","Epoch 19, Loss: 0.6866059523038189\n","Epoch 29, Loss: 0.6808605817231265\n","Epoch 39, Loss: 0.6775175796614753\n","Epoch 49, Loss: 0.6789248642897365\n","Epoch 59, Loss: 0.676546432153143\n","Epoch 69, Loss: 0.6754594222463742\n","Epoch 79, Loss: 0.6751353740692139\n","Epoch 89, Loss: 0.6743766740717069\n","Epoch 99, Loss: 0.6721614105532868\n","Validation loss: 0.6428451931476593\n","F1 Score: 0.17602996254681647\n","Epoch 9, Loss: 2.0266811474405153\n","Epoch 19, Loss: 1.9837405248121782\n","Epoch 29, Loss: 1.9395116423115586\n","Epoch 39, Loss: 1.8887245609904781\n","Epoch 49, Loss: 1.8502882267489578\n","Epoch 59, Loss: 1.8192240469383472\n","Epoch 69, Loss: 1.7692578958742546\n","Epoch 79, Loss: 1.7326789769259365\n","Epoch 89, Loss: 1.691570176018609\n","Epoch 99, Loss: 1.6612364005560827\n","Validation loss: 1.6881032943725587\n","F1 Score: 0.1603864734299517\n","Epoch 9, Loss: 0.6760429953685915\n","Epoch 19, Loss: 0.6672933652545466\n","Epoch 29, Loss: 0.6714441110991468\n","Epoch 39, Loss: 0.6668122579353024\n","Epoch 49, Loss: 0.6670614074576985\n","Epoch 59, Loss: 0.6701259272869187\n","Epoch 69, Loss: 0.6710219852852098\n","Epoch 79, Loss: 0.66662500482617\n","Epoch 89, Loss: 0.668724058553426\n","Epoch 99, Loss: 0.6701820306103639\n","Validation loss: 0.6469981634616851\n","F1 Score: 0.17464788732394365\n"]}],"source":["def get_mnli_score(word_embeddings):\n","\n","    # Convert the sentence pairs to embeddings\n","    embeddings = [(avg_feature_vector(s1, word_embeddings, num_features=CFG.embedding_dim), avg_feature_vector(s2, word_embeddings, num_features=CFG.embedding_dim)) for s1, s2 in sentence_pairs]\n","\n","    # Split the data into a training set and a validation set\n","    train_embeddings, val_embeddings, train_scores, val_scores = train_test_split(embeddings, similarity_scores, test_size=0.2)\n","\n","    # Create DataLoaders\n","    train_dataloader = DataLoader(SentencePairDataset(train_embeddings, train_scores), batch_size=32, shuffle=True)\n","    val_dataloader = DataLoader(SentencePairDataset(val_embeddings, val_scores), batch_size=32)\n","\n","    # Instantiate the model and define the loss and optimizer\n","    model = STSBModel(CFG.embedding_dim).to(CFG.device)\n","    # Choose a loss function and an optimizer\n","    loss_fn = nn.MSELoss()\n","    optimizer = optim.Adam(model.parameters(), lr = 1e-5)\n","\n","    # Training loop\n","    for epoch in range(100):\n","        losses = []\n","        for embeddings, scores in train_dataloader:\n","            embeddings1 = torch.tensor(embeddings[0], dtype=torch.float32).to(CFG.device)\n","            embeddings2 = torch.tensor(embeddings[1], dtype=torch.float32).to(CFG.device)\n","            scores = torch.tensor(scores, dtype=torch.float32).to(CFG.device)\n","            outputs = model(embeddings1, embeddings2)\n","            loss = loss_fn(outputs, scores)\n","            losses.append(loss.item())\n","            loss.backward()\n","            optimizer.step()\n","            optimizer.zero_grad()\n","\n","        if((epoch+1)%10==0):\n","            print(f\"Epoch {epoch}, Loss: {np.mean(losses)}\")\n","\n","    # Evaluation\n","    model.eval()\n","    total_loss, total_count = 0, 0\n","    y_true, y_pred = [], []\n","    with torch.no_grad():\n","        for embeddings, scores in val_dataloader:\n","            embeddings1 = torch.tensor(embeddings[0], dtype=torch.float32).to(CFG.device)\n","            embeddings2 = torch.tensor(embeddings[1], dtype=torch.float32).to(CFG.device)\n","            scores = torch.tensor(scores, dtype=torch.float32).to(CFG.device)\n","            outputs = model(embeddings1, embeddings2)\n","            loss = loss_fn(outputs, scores)\n","            total_loss += loss.item()\n","            total_count += 1\n","            outputs = [item for item_l in outputs.cpu().tolist() for item in item_l]\n","            y_true.extend(scores.cpu().tolist())\n","            y_pred.extend(outputs)\n","    avg_loss = total_loss / total_count\n","    print(f\"Validation loss: {avg_loss}\")\n","    # Compute evaluation metrics\n","    y_pred = [round(pred) for pred in y_pred]\n","    f1 = f1_score(y_true, y_pred, average=\"macro\")\n","    print(f\"F1 Score: {f1}\")\n","    return f1\n","downstream_results['MNLI Biased F1'] = get_mnli_score(mnli_word_dict)\n","downstream_results['MNLI Soft-Debiased F1'] = get_mnli_score(mnli_soft_debiased_word_dict)\n","downstream_results['MNLI DSD F1'] = get_mnli_score(mnli_DSD_word_dict)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AKY5GruQDt9F"},"outputs":[],"source":["splits = {'train': 'train.jsonl', 'validation': 'validation.jsonl', 'test': 'test.jsonl'}\n","rte_df = pd.read_json(\"hf://datasets/SetFit/rte/\" + splits[\"train\"], lines=True)\n","\n","sentence_pairs = [(row[\"text1\"], row[\"text2\"]) for _, row in rte_df.iterrows()]\n","similarity_scores = [row[\"label\"] for _,row in rte_df.iterrows()]\n","\n","stop_words = set(stopwords.words('english'))\n","\n","if not os.path.isfile(CFG.rte_word_vectors):\n","    def preprocess_text(text):\n","        tokens = nltk.word_tokenize(text.lower())\n","        filtered_tokens = [word for word in tokens if word.isalpha() and word not in stop_words]\n","        return filtered_tokens\n","\n","    sentences = []\n","    for  pair in sentence_pairs:\n","        sentence1, sentence2 = pair[0], pair[1]\n","\n","        sentences.append(sentence1)\n","        sentences.append(sentence2)\n","\n","    sentences = [preprocess_text(sentence) for sentence in sentences]\n","\n","    rte_words = set()\n","    for sentence in sentences:\n","        for word in sentence:\n","            rte_words.add(word)\n","\n","    rte_words = list(rte_words)\n","    rte_word_embeddings = get_word_embeddings(rte_words, lm_model)\n","    rte_word_dict = {word: embedding for (word, embedding) in zip(rte_words, rte_word_embeddings)}\n","    pickle.dump(rte_word_dict, open(CFG.rte_word_vectors, \"wb\"))\n","else:\n","    rte_word_dict = pickle.load(open(CFG.rte_word_vectors, \"rb\"))\n","rte_soft_debiased_word_dict = Soft_Debias(debias_matrix, rte_word_dict)\n","rte_DSD_word_dict = DSD_Debias(debias_model, rte_word_dict)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p97wj-pjD4-v","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1726154003444,"user_tz":-330,"elapsed":199728,"user":{"displayName":"Aishik Rakshit","userId":"15122983906308089605"}},"outputId":"a19d6351-6203-463f-9178-e680f8493139"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 9, Loss: 1.1355562191160897\n","Epoch 19, Loss: 1.1144213808907404\n","Epoch 29, Loss: 1.094013812049987\n","Epoch 39, Loss: 1.0713033430160037\n","Epoch 49, Loss: 1.0464350609552293\n","Epoch 59, Loss: 1.0219588166191464\n","Epoch 69, Loss: 1.008268480263059\n","Epoch 79, Loss: 0.9819171693589952\n","Epoch 89, Loss: 0.9610963889530727\n","Epoch 99, Loss: 0.9380814575013661\n","Validation loss: 0.9321514219045639\n","F1 Score: 0.33511348464619495\n","Epoch 9, Loss: 0.25036372528189704\n","Epoch 19, Loss: 0.24997870434844305\n","Epoch 29, Loss: 0.2501558931100936\n","Epoch 39, Loss: 0.2500100289545362\n","Epoch 49, Loss: 0.2504214717755242\n","Epoch 59, Loss: 0.250157935751809\n","Epoch 69, Loss: 0.2503057692259077\n","Epoch 79, Loss: 0.250226340596638\n","Epoch 89, Loss: 0.2500469597086074\n","Epoch 99, Loss: 0.25009381652824464\n","Validation loss: 0.24996217526495457\n","F1 Score: 0.3421400264200793\n","Epoch 9, Loss: 0.41864681835212403\n","Epoch 19, Loss: 0.40580071248705424\n","Epoch 29, Loss: 0.39713827579740496\n","Epoch 39, Loss: 0.3879440161916945\n","Epoch 49, Loss: 0.37923159296550446\n","Epoch 59, Loss: 0.3709074358145396\n","Epoch 69, Loss: 0.3649255389732028\n","Epoch 79, Loss: 0.35717957596930244\n","Epoch 89, Loss: 0.34600336837863166\n","Epoch 99, Loss: 0.3435124589337243\n","Validation loss: 0.3352399403229356\n","F1 Score: 0.3377659574468085\n"]}],"source":["def get_rte_score(word_embeddings):\n","\n","    # Convert the sentence pairs to embeddings\n","    embeddings = [(avg_feature_vector(s1, word_embeddings, num_features=CFG.embedding_dim), avg_feature_vector(s2, word_embeddings, num_features=CFG.embedding_dim)) for s1, s2 in sentence_pairs]\n","\n","    # Split the data into a training set and a validation set\n","    train_embeddings, val_embeddings, train_scores, val_scores = train_test_split(embeddings, similarity_scores, test_size=0.2)\n","\n","    # Create DataLoaders\n","    train_dataloader = DataLoader(SentencePairDataset(train_embeddings, train_scores), batch_size=32, shuffle=True)\n","    val_dataloader = DataLoader(SentencePairDataset(val_embeddings, val_scores), batch_size=32)\n","\n","    # Instantiate the model and define the loss and optimizer\n","    model = STSBModel(CFG.embedding_dim).to(CFG.device)\n","    # Choose a loss function and an optimizer\n","    loss_fn = nn.MSELoss()\n","    optimizer = optim.Adam(model.parameters(), lr = 1e-5)\n","\n","    # Training loop\n","    for epoch in range(100):\n","        losses = []\n","        for embeddings, scores in train_dataloader:\n","            embeddings1 = torch.tensor(embeddings[0], dtype=torch.float32).to(CFG.device)\n","            embeddings2 = torch.tensor(embeddings[1], dtype=torch.float32).to(CFG.device)\n","            scores = torch.tensor(scores, dtype=torch.float32).to(CFG.device)\n","            outputs = model(embeddings1, embeddings2)\n","            loss = loss_fn(outputs, scores)\n","            losses.append(loss.item())\n","            loss.backward()\n","            optimizer.step()\n","            optimizer.zero_grad()\n","\n","        if((epoch+1)%10==0):\n","            print(f\"Epoch {epoch}, Loss: {np.mean(losses)}\")\n","\n","    # Evaluation\n","    model.eval()\n","    total_loss, total_count = 0, 0\n","    y_true, y_pred = [], []\n","    with torch.no_grad():\n","        for embeddings, scores in val_dataloader:\n","            embeddings1 = torch.tensor(embeddings[0], dtype=torch.float32).to(CFG.device)\n","            embeddings2 = torch.tensor(embeddings[1], dtype=torch.float32).to(CFG.device)\n","            scores = torch.tensor(scores, dtype=torch.float32).to(CFG.device)\n","            outputs = model(embeddings1, embeddings2)\n","            loss = loss_fn(outputs, scores)\n","            total_loss += loss.item()\n","            total_count += 1\n","            outputs = [item for item_l in outputs.cpu().tolist() for item in item_l]\n","            y_true.extend(scores.cpu().tolist())\n","            y_pred.extend(outputs)\n","    avg_loss = total_loss / total_count\n","    print(f\"Validation loss: {avg_loss}\")\n","    # Compute evaluation metrics\n","    y_pred = [round(pred) for pred in y_pred]\n","    f1 = f1_score(y_true, y_pred, average = \"macro\")\n","    print(f\"F1 Score: {f1}\")\n","    return f1\n","\n","downstream_results['RTE Biased F1'] = get_rte_score(rte_word_dict)\n","downstream_results['RTE Soft-Debiased F1'] = get_rte_score(rte_soft_debiased_word_dict)\n","downstream_results['RTE DSD F1'] = get_rte_score(rte_DSD_word_dict)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PgD37hM8dyqI"},"outputs":[],"source":["splits = {'train': 'train.jsonl', 'validation': 'validation.jsonl', 'test': 'test.jsonl'}\n","wnli_df = pd.read_json(\"hf://datasets/SetFit/wnli/\" + splits[\"train\"], lines=True)\n","\n","sentence_pairs = [(row[\"text1\"], row[\"text2\"]) for _, row in wnli_df.iterrows()]\n","similarity_scores = [row[\"label\"] for _,row in wnli_df.iterrows()]\n","\n","stop_words = set(stopwords.words('english'))\n","\n","if not os.path.isfile(CFG.wnli_word_vectors):\n","    def preprocess_text(text):\n","        tokens = nltk.word_tokenize(text.lower())\n","        filtered_tokens = [word for word in tokens if word.isalpha() and word not in stop_words]\n","        return filtered_tokens\n","\n","    sentences = []\n","    for  pair in sentence_pairs:\n","        sentence1, sentence2 = pair[0], pair[1]\n","\n","        sentences.append(sentence1)\n","        sentences.append(sentence2)\n","\n","    sentences = [preprocess_text(sentence) for sentence in sentences]\n","\n","    wnli_words = set()\n","    for sentence in sentences:\n","        for word in sentence:\n","            wnli_words.add(word)\n","\n","    wnli_words = list(wnli_words)\n","    wnli_word_embeddings = get_word_embeddings(wnli_words, lm_model)\n","    wnli_word_dict = {word: embedding for (word, embedding) in zip(wnli_words, wnli_word_embeddings)}\n","    pickle.dump(wnli_word_dict, open(CFG.wnli_word_vectors, \"wb\"))\n","else:\n","    wnli_word_dict = pickle.load(open(CFG.wnli_word_vectors, \"rb\"))\n","wnli_soft_debiased_word_dict = Soft_Debias(debias_matrix, wnli_word_dict)\n","wnli_DSD_word_dict = DSD_Debias(debias_model, wnli_word_dict)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bPvGci0dEv83","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1726154009096,"user_tz":-330,"elapsed":11,"user":{"displayName":"Aishik Rakshit","userId":"15122983906308089605"}},"outputId":"161fbdb3-f1a2-4b04-8911-56f46c5aa1c5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["635"]},"metadata":{},"execution_count":41}],"source":["len(sentence_pairs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"10VuSSxKd8qh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1726154191116,"user_tz":-330,"elapsed":182030,"user":{"displayName":"Aishik Rakshit","userId":"15122983906308089605"}},"outputId":"5a46f10a-4728-4228-be2f-8d88a77c129c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 99, Loss: 0.2501188050955534\n","Epoch 199, Loss: 0.2497354205697775\n","Epoch 299, Loss: 0.24977081175893545\n","Epoch 399, Loss: 0.2497796043753624\n","Epoch 499, Loss: 0.24978133104741573\n","Epoch 599, Loss: 0.2498101880773902\n","Epoch 699, Loss: 0.24984606634825468\n","Epoch 799, Loss: 0.2497302107512951\n","Epoch 899, Loss: 0.2497857715934515\n","Epoch 999, Loss: 0.2497069826349616\n","Validation loss: 0.25141141563653946\n","F1 Score: 0.32085561497326204\n","Epoch 99, Loss: 0.2526200274005532\n","Epoch 199, Loss: 0.25026796851307154\n","Epoch 299, Loss: 0.2500595673918724\n","Epoch 399, Loss: 0.2502836184576154\n","Epoch 499, Loss: 0.24999982118606567\n","Epoch 599, Loss: 0.25005631148815155\n","Epoch 699, Loss: 0.25019698217511177\n","Epoch 799, Loss: 0.25007068924605846\n","Epoch 899, Loss: 0.25000139605253935\n","Epoch 999, Loss: 0.2499609887599945\n","Validation loss: 0.2500137835741043\n","F1 Score: 0.33507853403141363\n","Epoch 99, Loss: 0.25001147016882896\n","Epoch 199, Loss: 0.2500285655260086\n","Epoch 299, Loss: 0.25095160864293575\n","Epoch 399, Loss: 0.2500615967437625\n","Epoch 499, Loss: 0.2500301543623209\n","Epoch 599, Loss: 0.25003540236502886\n","Epoch 699, Loss: 0.25001434702426195\n","Epoch 799, Loss: 0.25005126278847456\n","Epoch 899, Loss: 0.2500238921493292\n","Epoch 999, Loss: 0.25004643481224775\n","Validation loss: 0.24976424872875214\n","F1 Score: 0.34536082474226804\n"]}],"source":["def get_wnli_score(word_embeddings):\n","\n","    # Convert the sentence pairs to embeddings\n","    embeddings = [(avg_feature_vector(s1, word_embeddings, num_features=CFG.embedding_dim), avg_feature_vector(s2, word_embeddings, num_features=CFG.embedding_dim)) for s1, s2 in sentence_pairs]\n","\n","    # Split the data into a training set and a validation set\n","    train_embeddings, val_embeddings, train_scores, val_scores = train_test_split(embeddings, similarity_scores, test_size=0.2)\n","\n","    # Create DataLoaders\n","    train_dataloader = DataLoader(SentencePairDataset(train_embeddings, train_scores), batch_size=32, shuffle=True)\n","    val_dataloader = DataLoader(SentencePairDataset(val_embeddings, val_scores), batch_size=32)\n","\n","    # Instantiate the model and define the loss and optimizer\n","    model = STSBModel(CFG.embedding_dim).to(CFG.device)\n","    # Choose a loss function and an optimizer\n","    loss_fn = nn.MSELoss()\n","    optimizer = optim.Adam(model.parameters(), lr = 1e-3)\n","\n","    # Training loop\n","    for epoch in range(1000):\n","        losses = []\n","        for embeddings, scores in train_dataloader:\n","            embeddings1 = torch.tensor(embeddings[0], dtype=torch.float32).to(CFG.device)\n","            embeddings2 = torch.tensor(embeddings[1], dtype=torch.float32).to(CFG.device)\n","            scores = torch.tensor(scores, dtype=torch.float32).to(CFG.device)\n","            outputs = model(embeddings1, embeddings2)\n","            loss = loss_fn(outputs, scores)\n","            losses.append(loss.item())\n","            loss.backward()\n","            optimizer.step()\n","            optimizer.zero_grad()\n","\n","        if((epoch+1)%100==0):\n","            print(f\"Epoch {epoch}, Loss: {np.mean(losses)}\")\n","\n","    # Evaluation\n","    model.eval()\n","    total_loss, total_count = 0, 0\n","    y_true, y_pred = [], []\n","    with torch.no_grad():\n","        for embeddings, scores in val_dataloader:\n","            embeddings1 = torch.tensor(embeddings[0], dtype=torch.float32).to(CFG.device)\n","            embeddings2 = torch.tensor(embeddings[1], dtype=torch.float32).to(CFG.device)\n","            scores = torch.tensor(scores, dtype=torch.float32).to(CFG.device)\n","            outputs = model(embeddings1, embeddings2)\n","            loss = loss_fn(outputs, scores)\n","            total_loss += loss.item()\n","            total_count += 1\n","            outputs = [item for item_l in outputs.cpu().tolist() for item in item_l]\n","            y_true.extend(scores.cpu().tolist())\n","            y_pred.extend(outputs)\n","    avg_loss = total_loss / total_count\n","    print(f\"Validation loss: {avg_loss}\")\n","    # Compute evaluation metrics\n","    y_pred = [round(pred) for pred in y_pred]\n","    f1 = f1_score(y_true, y_pred, average=\"macro\")\n","    print(f\"F1 Score: {f1}\")\n","    return f1\n","\n","downstream_results['WNLI Biased F1'] = get_wnli_score(wnli_word_dict)\n","downstream_results['WNLI Soft-Debiased F1'] = get_wnli_score(wnli_soft_debiased_word_dict)\n","downstream_results['WNLI DSD F1'] = get_wnli_score(wnli_DSD_word_dict)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fObT4T1hdzEa"},"outputs":[],"source":["save_results(downstream_results, CFG.downstream_results_filename)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KnA5MDTAuKum"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[],"mount_file_id":"1skTU0jLYB8Ab8pmsCIv3AMNU-A0vv7eh","authorship_tag":"ABX9TyP0FYQ4BWISSGH6qUZ9FRGu"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"5f7201d2ac834ad69b49fea417287133":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9ef2fa7fe90346ba95333ae83de07b05","IPY_MODEL_43badb0a04a5473e96e09e951ec5af95","IPY_MODEL_2ba6876f5eea439680e469c2dd006f9c"],"layout":"IPY_MODEL_747f0a51da1240aba543ed4826cba403"}},"9ef2fa7fe90346ba95333ae83de07b05":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5c9bd5ae2450477c86553ef09f6a8a64","placeholder":"​","style":"IPY_MODEL_ea12cdba34c444b5a3ca7256ccedfc86","value":"README.md: 100%"}},"43badb0a04a5473e96e09e951ec5af95":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2d68b01b9be54882906fe07a1551288c","max":35296,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2d311d0705f540a698bfc69b66316283","value":35296}},"2ba6876f5eea439680e469c2dd006f9c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_368c33ee46a04040a49caa2c2cb36921","placeholder":"​","style":"IPY_MODEL_79a2d60e4b9a4f24942d84ff9a0bd5bc","value":" 35.3k/35.3k [00:00&lt;00:00, 2.61MB/s]"}},"747f0a51da1240aba543ed4826cba403":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c9bd5ae2450477c86553ef09f6a8a64":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea12cdba34c444b5a3ca7256ccedfc86":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2d68b01b9be54882906fe07a1551288c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2d311d0705f540a698bfc69b66316283":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"368c33ee46a04040a49caa2c2cb36921":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"79a2d60e4b9a4f24942d84ff9a0bd5bc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ca67c328697c48a0b07a19cb40b69b88":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_400f2b73230c4b08bac2f0a0029dce9d","IPY_MODEL_c84ad826dc6f45a8b8570eba55924110","IPY_MODEL_09db358e132e433088dacc19c4389e03"],"layout":"IPY_MODEL_bd21efa1d3984f76b9d7110ed88a0896"}},"400f2b73230c4b08bac2f0a0029dce9d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ca7e3dc8990545368efaa81e0a5046bd","placeholder":"​","style":"IPY_MODEL_f219a948d733437caca190cb9fd7cd0f","value":"train-00000-of-00001.parquet: 100%"}},"c84ad826dc6f45a8b8570eba55924110":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_03ecea16949f4a76a20607e425a4c477","max":502065,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8546978d108e4f42b0f29537d3f190f9","value":502065}},"09db358e132e433088dacc19c4389e03":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_433dfb0ee21546859555511028459ec3","placeholder":"​","style":"IPY_MODEL_fe313e4e92bd48b58fa6c1892d41c023","value":" 502k/502k [00:00&lt;00:00, 6.81MB/s]"}},"bd21efa1d3984f76b9d7110ed88a0896":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ca7e3dc8990545368efaa81e0a5046bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f219a948d733437caca190cb9fd7cd0f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"03ecea16949f4a76a20607e425a4c477":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8546978d108e4f42b0f29537d3f190f9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"433dfb0ee21546859555511028459ec3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fe313e4e92bd48b58fa6c1892d41c023":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"36f537d725a444e2b72452cffc5b020b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d37f67dc74724bd8a6759c69d94beacf","IPY_MODEL_4116d13c03ab4408be457ac7ccc162b8","IPY_MODEL_fbaa8dabdf264785b2dacfe8b9a5c3bd"],"layout":"IPY_MODEL_c41def39aa4c49778b5131967eed313c"}},"d37f67dc74724bd8a6759c69d94beacf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c0109c0e34e84a33bafb2e16233e6122","placeholder":"​","style":"IPY_MODEL_a483c130bf644e12bf318c96f009a51d","value":"validation-00000-of-00001.parquet: 100%"}},"4116d13c03ab4408be457ac7ccc162b8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_56ab97f1dd9a45c198f41b8d6f1005be","max":150622,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f0cd88aa7cf044328646aba83396e824","value":150622}},"fbaa8dabdf264785b2dacfe8b9a5c3bd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c40fceda3f594e8a8f76d238511b0100","placeholder":"​","style":"IPY_MODEL_fb486617a0ec4389a8f32ca14e957630","value":" 151k/151k [00:00&lt;00:00, 11.6MB/s]"}},"c41def39aa4c49778b5131967eed313c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c0109c0e34e84a33bafb2e16233e6122":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a483c130bf644e12bf318c96f009a51d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"56ab97f1dd9a45c198f41b8d6f1005be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f0cd88aa7cf044328646aba83396e824":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c40fceda3f594e8a8f76d238511b0100":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb486617a0ec4389a8f32ca14e957630":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c21bcec83d3744639d4afcfe201cabf4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_484e7a0e6c9c474fb5ab44fff54ce2e2","IPY_MODEL_4e6980734e1049ca8431620290eb8396","IPY_MODEL_05794156f4fe4c32bb6398113ce8986f"],"layout":"IPY_MODEL_545d8a6b56ac4d0eacdad4ab79824399"}},"484e7a0e6c9c474fb5ab44fff54ce2e2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f247bf1907704b4caa620d7ca2bb6b36","placeholder":"​","style":"IPY_MODEL_ab6f1a25da7a4475a8a743786b217705","value":"test-00000-of-00001.parquet: 100%"}},"4e6980734e1049ca8431620290eb8396":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9f655f10936f4d0ba4b2ae8d2912cb42","max":114296,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2feecf9d00754e89920eb70eeb04592c","value":114296}},"05794156f4fe4c32bb6398113ce8986f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_992c7d6d437f437297983ffd0f0bc3c7","placeholder":"​","style":"IPY_MODEL_260aef7ec4344a128e2e46f7269afd92","value":" 114k/114k [00:00&lt;00:00, 8.28MB/s]"}},"545d8a6b56ac4d0eacdad4ab79824399":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f247bf1907704b4caa620d7ca2bb6b36":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab6f1a25da7a4475a8a743786b217705":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9f655f10936f4d0ba4b2ae8d2912cb42":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2feecf9d00754e89920eb70eeb04592c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"992c7d6d437f437297983ffd0f0bc3c7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"260aef7ec4344a128e2e46f7269afd92":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"25b6f76ba518463fb3e6f722dc24249a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a49941ea16a540719dac5c42523fc390","IPY_MODEL_9d8dcebe0f404d4fbb8196bc160abfe2","IPY_MODEL_355b3bebcd0141b8bd60be8d7f425c46"],"layout":"IPY_MODEL_d3f2a92350954318af303d87a68a3437"}},"a49941ea16a540719dac5c42523fc390":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_688ef6e43cae4bbab3fece6d16b3f13e","placeholder":"​","style":"IPY_MODEL_3b2551f2d7d840c4b8bcb50a551d2321","value":"Generating train split: 100%"}},"9d8dcebe0f404d4fbb8196bc160abfe2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_751c2154c6f544af9059bf1c6d522f9e","max":5749,"min":0,"orientation":"horizontal","style":"IPY_MODEL_897ec2dd67e4442187a90bb053ab3a94","value":5749}},"355b3bebcd0141b8bd60be8d7f425c46":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3bf459f1f2404e05b06bb7879892de96","placeholder":"​","style":"IPY_MODEL_10bf61152ecb4ecd89b777decbf883ce","value":" 5749/5749 [00:00&lt;00:00, 255982.65 examples/s]"}},"d3f2a92350954318af303d87a68a3437":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"688ef6e43cae4bbab3fece6d16b3f13e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b2551f2d7d840c4b8bcb50a551d2321":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"751c2154c6f544af9059bf1c6d522f9e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"897ec2dd67e4442187a90bb053ab3a94":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3bf459f1f2404e05b06bb7879892de96":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"10bf61152ecb4ecd89b777decbf883ce":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d7d486bfbacf4a54b631916fcd16751c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d6083f65ef5b42efa05f25ff7cc5f4b5","IPY_MODEL_81cda875f06f4d2f826741595088f11a","IPY_MODEL_3d86606bbbcb48d3ae0e2c683a9074fb"],"layout":"IPY_MODEL_aa39950989014445b42fcfdf89da7a5d"}},"d6083f65ef5b42efa05f25ff7cc5f4b5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5b4268a87e9c48659140d0895a2724a4","placeholder":"​","style":"IPY_MODEL_875d2ddface74faebeed80b50319d741","value":"Generating validation split: 100%"}},"81cda875f06f4d2f826741595088f11a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6b6d97b4c04d4f72a1a83bb13da2f313","max":1500,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ce12e7fe2a184875bcb027a61700dbbf","value":1500}},"3d86606bbbcb48d3ae0e2c683a9074fb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_574d9c23052b4197adb9bf3762353368","placeholder":"​","style":"IPY_MODEL_03491f6d3fe143558c91b73d5aa237d9","value":" 1500/1500 [00:00&lt;00:00, 90711.19 examples/s]"}},"aa39950989014445b42fcfdf89da7a5d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b4268a87e9c48659140d0895a2724a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"875d2ddface74faebeed80b50319d741":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6b6d97b4c04d4f72a1a83bb13da2f313":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce12e7fe2a184875bcb027a61700dbbf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"574d9c23052b4197adb9bf3762353368":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"03491f6d3fe143558c91b73d5aa237d9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"37ecf2a0df724879a35279d7f1e3922e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b7820465ec53409d85276b67c4f54214","IPY_MODEL_731be271ca5244379c91cf1b7ac71046","IPY_MODEL_00176395e029495abdb9514e31c7c480"],"layout":"IPY_MODEL_ef7723121ec74503a945678718531ac1"}},"b7820465ec53409d85276b67c4f54214":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_07e353dbcfdb4be68be68cfd1d8de407","placeholder":"​","style":"IPY_MODEL_3bb50b34ad7f4d639a39aebdc67392e0","value":"Generating test split: 100%"}},"731be271ca5244379c91cf1b7ac71046":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a8f91f32b27d482ab8047deeb941e0ba","max":1379,"min":0,"orientation":"horizontal","style":"IPY_MODEL_58932168ab164fd9a695583a00ca5d17","value":1379}},"00176395e029495abdb9514e31c7c480":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9def10b9b1224a2dbe36ae6c7ace2bd0","placeholder":"​","style":"IPY_MODEL_7b34c61b3a754f49accfd61437d4ccde","value":" 1379/1379 [00:00&lt;00:00, 84746.45 examples/s]"}},"ef7723121ec74503a945678718531ac1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"07e353dbcfdb4be68be68cfd1d8de407":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3bb50b34ad7f4d639a39aebdc67392e0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a8f91f32b27d482ab8047deeb941e0ba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"58932168ab164fd9a695583a00ca5d17":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9def10b9b1224a2dbe36ae6c7ace2bd0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b34c61b3a754f49accfd61437d4ccde":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6c6f2aae5a5842dcb8f484f4975c5455":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_4ade34a2c7d345e1a3c08d508f18c1f8","IPY_MODEL_1a6d41a5bf33403cb040875872816dfa","IPY_MODEL_e98cd7cc8bd9452abd7756b92787c9d3","IPY_MODEL_d54c4f695adb4a9db42e6b71e87864f7","IPY_MODEL_075636d3c1f64936a427d5d3851933ee"],"layout":"IPY_MODEL_87636363c1f942edae2f6416153dd78a"}},"4ade34a2c7d345e1a3c08d508f18c1f8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a4aba6b7f3d547ddbb17adedf6a64d6a","placeholder":"​","style":"IPY_MODEL_983c3a905a064488a1d18eea117fb7ca","value":"<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"}},"1a6d41a5bf33403cb040875872816dfa":{"model_module":"@jupyter-widgets/controls","model_name":"PasswordModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"PasswordModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"PasswordView","continuous_update":true,"description":"Token:","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_a34919f15eee447395b8404a0b579391","placeholder":"​","style":"IPY_MODEL_f168ced8d2c442439022b23310a07440","value":""}},"e98cd7cc8bd9452abd7756b92787c9d3":{"model_module":"@jupyter-widgets/controls","model_name":"CheckboxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"CheckboxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"CheckboxView","description":"Add token as git credential?","description_tooltip":null,"disabled":false,"indent":true,"layout":"IPY_MODEL_a9f52f78cfc24eb1a2d3064f02c018e0","style":"IPY_MODEL_62e94f1c1c90427c87589d9b6d10e737","value":true}},"d54c4f695adb4a9db42e6b71e87864f7":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"","description":"Login","disabled":false,"icon":"","layout":"IPY_MODEL_ee4ad713e8ad4c07a7c939bfeebc95f1","style":"IPY_MODEL_f960f975d1b24158bc5041b112bda1da","tooltip":""}},"075636d3c1f64936a427d5d3851933ee":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_33c4b25fc3d8477891cbc4ee89c30c4c","placeholder":"​","style":"IPY_MODEL_5358ef271e1d4315a188b0142770e6ec","value":"\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"}},"87636363c1f942edae2f6416153dd78a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":"center","align_self":null,"border":null,"bottom":null,"display":"flex","flex":null,"flex_flow":"column","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"50%"}},"a4aba6b7f3d547ddbb17adedf6a64d6a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"983c3a905a064488a1d18eea117fb7ca":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a34919f15eee447395b8404a0b579391":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f168ced8d2c442439022b23310a07440":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a9f52f78cfc24eb1a2d3064f02c018e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"62e94f1c1c90427c87589d9b6d10e737":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ee4ad713e8ad4c07a7c939bfeebc95f1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f960f975d1b24158bc5041b112bda1da":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"33c4b25fc3d8477891cbc4ee89c30c4c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5358ef271e1d4315a188b0142770e6ec":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9d60968f2fd2495bbe6e863e37e3d789":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_83f88bb619e14aebbe23eea55fc03dcd","IPY_MODEL_a001c13232de47299021bd7d1fbf16ce","IPY_MODEL_f914a2573f7c4ec786b1b3784d001565"],"layout":"IPY_MODEL_064ba35d5bd546c191d66fd27c9b01f0"}},"83f88bb619e14aebbe23eea55fc03dcd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c96875a3651e46c1b1f2aa3197450784","placeholder":"​","style":"IPY_MODEL_d11f92ceb6c84794a92581dba8501db6","value":"Loading checkpoint shards: 100%"}},"a001c13232de47299021bd7d1fbf16ce":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_182ee0900a7f4b0b9204b2f55a14f760","max":4,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ffbeb6421bbd425fbd5f2846da278851","value":4}},"f914a2573f7c4ec786b1b3784d001565":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1335d11d343a4b88878bac2edeb31d8a","placeholder":"​","style":"IPY_MODEL_7c1a54f6808b43de8fe91b31a4b175ce","value":" 4/4 [00:11&lt;00:00,  2.34s/it]"}},"064ba35d5bd546c191d66fd27c9b01f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c96875a3651e46c1b1f2aa3197450784":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d11f92ceb6c84794a92581dba8501db6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"182ee0900a7f4b0b9204b2f55a14f760":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ffbeb6421bbd425fbd5f2846da278851":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1335d11d343a4b88878bac2edeb31d8a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c1a54f6808b43de8fe91b31a4b175ce":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}